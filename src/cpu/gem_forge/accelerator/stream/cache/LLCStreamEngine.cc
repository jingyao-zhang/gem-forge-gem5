
#include "LLCStreamEngine.hh"
#include "LLCStreamAtomicLockManager.hh"
#include "LLCStreamCommitController.hh"
#include "LLCStreamMigrationController.hh"
#include "LLCStreamNDCController.hh"
#include "LLCStreamRangeBuilder.hh"
#include "MLCStreamEngine.hh"
#include "StreamRequestBuffer.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

// Generated by slicc.
#include "mem/ruby/protocol/StreamMigrateRequestMsg.hh"
#include "mem/simple_mem.hh"

#include "cpu/gem_forge/accelerator/stream/stream_atomic_op.hh"
#include "cpu/gem_forge/accelerator/stream/stream_engine.hh"
#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/LLCRubyStreamBase.hh"
#include "debug/LLCRubyStreamLife.hh"
#include "debug/LLCRubyStreamMulticast.hh"
#include "debug/LLCRubyStreamNotIssue.hh"
#include "debug/LLCRubyStreamReduce.hh"
#include "debug/LLCRubyStreamStore.hh"
#include "debug/StreamRangeSync.hh"
#define DEBUG_TYPE LLCRubyStreamBase
#include "../stream_log.hh"

#define LLCSE_DPRINTF(format, args...)                                         \
  DPRINTF(LLCRubyStreamBase, "[%s_SE%d]: " format,                             \
          this->curRemoteMachineType(), this->curRemoteBank(), ##args)

LLCStreamEngine::LLCStreamEngine(AbstractStreamAwareController *_controller,
                                 MessageBuffer *_streamMigrateMsgBuffer,
                                 MessageBuffer *_streamIssueMsgBuffer,
                                 MessageBuffer *_streamIndirectIssueMsgBuffer,
                                 MessageBuffer *_streamResponseMsgBuffer)
    : Consumer(_controller), controller(_controller),
      streamMigrateMsgBuffer(_streamMigrateMsgBuffer),
      streamIssueMsgBuffer(_streamIssueMsgBuffer),
      streamIndirectIssueMsgBuffer(_streamIndirectIssueMsgBuffer),
      streamResponseMsgBuffer(_streamResponseMsgBuffer),
      issueWidth(_controller->getLLCStreamEngineIssueWidth()),
      migrateWidth(_controller->getLLCStreamEngineMigrateWidth()),
      maxInflyRequests(8), maxInqueueRequests(2), translationBuffer(nullptr) {
  this->controller->registerLLCStreamEngine(this);
  this->commitController = m5::make_unique<LLCStreamCommitController>(this);
  this->atomicLockManager = m5::make_unique<LLCStreamAtomicLockManager>(this);
  this->ndcController = m5::make_unique<LLCStreamNDCController>(this);
  this->indReqBuffer = m5::make_unique<StreamRequestBuffer>(
      this->controller, this->streamIndirectIssueMsgBuffer, Cycles(1), 4);
  this->migrateController = m5::make_unique<LLCStreamMigrationController>(
      this->controller,
      this->controller->myParams
          ->neighbor_stream_threshold /* NeighborStreamsThreshold */,
      Cycles(this->controller->myParams->neighbor_migration_delay) /* Delay */
  );
}

LLCStreamEngine::~LLCStreamEngine() { this->streams.clear(); }

int LLCStreamEngine::getNumDirectStreams() const {
  return this->streams.size() + this->migratingStreams.size();
}

int LLCStreamEngine::getNumDirectStreamsWithStaticId(
    const DynamicStreamId &dynStreamId) const {
  int count = 0;
  for (auto dynS : this->streams) {
    if (dynS->getDynamicStreamId().staticId == dynStreamId.staticId) {
      count++;
    }
  }
  for (auto dynS : this->migratingStreams) {
    if (dynS->getDynamicStreamId().staticId == dynStreamId.staticId) {
      count++;
    }
  }
  return count;
}

int LLCStreamEngine::curRemoteBank() const {
  return this->controller->getMachineID().num;
}

MachineType LLCStreamEngine::myMachineType() const {
  return this->controller->getMachineID().getType();
}

const char *LLCStreamEngine::curRemoteMachineType() const {
  return this->controller->getMachineTypeString();
}

void LLCStreamEngine::receiveStreamConfigure(PacketPtr pkt) {

  // Initialize the translation buffer.
  this->initializeTranslationBuffer();

  auto streamConfigureData = *(pkt->getPtr<CacheStreamConfigureDataPtr>());
  LLCSE_DPRINTF("Received Pkt %#x, StreamConfigure %#x, initVAddr "
                "%#x, "
                "initPAddr %#x.\n",
                pkt, streamConfigureData, streamConfigureData->initVAddr,
                streamConfigureData->initPAddr);

  // Create the stream.
  auto S = LLCDynamicStream::getLLCStreamPanic(streamConfigureData->dynamicId);
  LLC_S_DPRINTF_(LLCRubyStreamLife, S->getDynamicStreamId(),
                 "Configure DirectStream InitAllocatedSlice %d "
                 "TotalTripCount %lld.\n",
                 streamConfigureData->initCreditedIdx, S->getTotalTripCount());
  S->configuredLLC(this->controller);

  // Add the initial credits.
  S->addCredit(streamConfigureData->initCreditedIdx);

  // Remember the stream to the CommitController if we have that.
  if (S->shouldRangeSync()) {
    this->commitController->registerStream(S);
  }

  // Check if we have indirect streams.
  for (const auto &edge : streamConfigureData->depEdges) {
    if (edge.type == CacheStreamConfigureData::DepEdge::Type::UsedBy) {
      auto &ISConfig = edge.data;
      // Let's create an indirect stream.
      auto IS = LLCDynamicStream::getLLCStreamPanic(ISConfig->dynamicId);
      LLC_S_DPRINTF_(LLCRubyStreamLife, IS->getDynamicStreamId(),
                     "Configure IndirectStream MemElementSize %d "
                     "TotalTripCount %lld.\n",
                     IS->getMemElementSize(), IS->getTotalTripCount());
      IS->configuredLLC(this->controller);
    }
  }

  // Release memory.
  *(pkt->getPtr<CacheStreamConfigureDataPtr>()) = nullptr;
  delete pkt;

  S->traceEvent(::LLVM::TDG::StreamFloatEvent::CONFIG);
  // Let's check if StreamEnd packet has arrived earlier.
  if (this->pendingStreamEndMsgs.count(S->getDynamicStreamId())) {
    S->terminate();
  } else {
    this->streams.emplace_back(S);
    this->addStreamToMulticastTable(S);
    // Let's schedule a wakeup event.
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::receiveStreamEnd(PacketPtr pkt) {
  auto endStreamDynamicId = *(pkt->getPtr<DynamicStreamId *>());
  LLC_S_DPRINTF_(LLCRubyStreamLife, *endStreamDynamicId,
                 "Received StreamEnd.\n");
  // Search for this stream.
  for (auto streamIter = this->streams.begin(), streamEnd = this->streams.end();
       streamIter != streamEnd; ++streamIter) {
    auto &S = *streamIter;
    if (S->getDynamicStreamId() == (*endStreamDynamicId)) {
      // Found it.
      // ? Can we just sliently release it?
      this->removeStreamFromMulticastTable(S);
      S->terminate();
      this->streams.erase(streamIter);
      // Don't forgot to release the memory.
      delete endStreamDynamicId;
      delete pkt;
      return;
    }
  }
  /**
   * ? No need to search in migratingStreams?
   * For migrating streams, the end message should be sent to the
   * destination llcBank.
   */

  /**
   * If not found, it is similar case as stream flow control message.
   * We are waiting for the stream to migrate here.
   * Add the message to the pending
   */
  this->pendingStreamEndMsgs.insert(*endStreamDynamicId);

  // Don't forgot to release the memory.
  delete endStreamDynamicId;
  delete pkt;
}

void LLCStreamEngine::receiveStreamMigrate(LLCDynamicStreamPtr stream,
                                           bool isCommit) {

  this->initializeTranslationBuffer();

  /**
   * Handle the case for commit migration.
   */
  if (isCommit) {
    LLC_S_DPRINTF_(StreamRangeSync, stream->getDynamicStreamId(),
                   "[Commit] Received migrate.\n");
    if (stream->isTerminated()) {
      LLC_S_DPRINTF_(StreamRangeSync, stream->getDynamicStreamId(),
                     "[Commit] Already terminated.\n");

    } else {
      this->commitController->registerStream(stream);
      this->scheduleEvent(Cycles(1));
    }
    return;
  }

  // Sanity check.
  Addr vaddr = stream->peekNextAllocVAddr();
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Paddr should always be valid to migrate a stream.");
  Addr paddrLine = makeLineAddress(paddr);
  assert(this->isPAddrHandledByMe(paddrLine) &&
         "Stream migrated to wrong LLC bank.\n");

  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (stream->hasIndirectDependent()) {
      // This is only enforced when there is dependent streams.
      assert(stream->inflyRequests == 0 &&
             "Stream migrated with inflyRequests.");
    }
    assert(!stream->hasIndirectElementReadyToIssue() &&
           "Stream migrated with readyIndirectElements.");
  }

  LLC_S_DPRINTF(stream->getDynamicStreamId(),
                "Received migrate. DirectStreams %llu.\n",
                this->streams.size());

  stream->migratingDone(this->controller);

  // Check for if the stream is already ended.
  if (this->pendingStreamEndMsgs.count(stream->getDynamicStreamId())) {
    stream->terminate();
    return;
  }

  this->streams.emplace_back(stream);
  this->addStreamToMulticastTable(stream);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamFlow(const DynamicStreamSliceId &sliceId) {
  // Simply append it to the list.
  LLC_SLICE_DPRINTF(sliceId, "Received stream flow [%lu, +%lu).\n",
                    sliceId.getStartIdx(), sliceId.getNumElements());
  this->pendingStreamFlowControlMsgs.push_back(sliceId);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamCommit(const DynamicStreamSliceId &sliceId) {
  LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                     "Received stream commit [%llu, %llu).\n",
                     sliceId.getStartIdx(), sliceId.getEndIdx());
  auto dynS = LLCDynamicStream::getLLCStream(sliceId.elementRange.streamId);
  if (!dynS) {
    // The stream is already released.
    return;
  }
  dynS->addCommitMessage(sliceId);
}

void LLCStreamEngine::receiveStreamDataVec(
    Cycles delayCycle, Addr paddrLine, const DynamicStreamSliceIdVec &sliceIds,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto readyCycle = this->controller->curCycle() + delayCycle;

  /**
   * Notice that we replace the data block here if we are using
   * back storage.
   */
  DataBlock loadValueBlock = dataBlock;
  auto rubySystem = this->controller->params()->ruby_system;
  if (rubySystem->getAccessBackingStore()) {
    // Get the data from backing store.
    RequestPtr req =
        std::make_shared<Request>(paddrLine, rubySystem->getBlockSizeBytes(),
                                  0 /* Flags */, 0 /* MasterId */);
    PacketPtr pkt = Packet::createRead(req);
    pkt->dataStatic(loadValueBlock.getDataMod(0 /* offset */));
    rubySystem->getPhysMem()->functionalAccess(pkt);
    delete pkt;
  }

  for (const auto &sliceId : sliceIds.sliceIds) {
    this->enqueueIncomingStreamDataMsg(readyCycle, sliceId, loadValueBlock,
                                       storeValueBlock);
  }
  this->scheduleEvent(Cycles(delayCycle));
}

void LLCStreamEngine::notifyStreamRequestMiss(
    const DynamicStreamSliceIdVec &sliceIds) {
  if (this->myMachineType() == MachineType::MachineType_L2Cache) {
    for (const auto &sliceId : sliceIds.sliceIds) {
      auto llcS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId());
      if (llcS) {
        auto S = llcS->getStaticStream();
        S->statistic.numMissL2++;
      }
    }
  }
}

void LLCStreamEngine::receiveStreamNDCRequest(PacketPtr pkt) {
  this->ndcController->receiveStreamNDCRequest(pkt);
}

void LLCStreamEngine::enqueueIncomingStreamDataMsg(
    Cycles readyCycle, const DynamicStreamSliceId &sliceId,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto iter = this->incomingStreamDataQueue.rbegin();
  for (auto end = this->incomingStreamDataQueue.rend(); iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      break;
    }
  }
  this->incomingStreamDataQueue.emplace(iter.base(), readyCycle, sliceId,
                                        dataBlock, storeValueBlock);
  // Some sanity check.
  if (this->incomingStreamDataQueue.size() > 100) {
    LLC_SLICE_PANIC(sliceId, "IncomingElementDataQueue overflow.");
  }
}

void LLCStreamEngine::drainIncomingStreamDataMsg() {
  auto curCycle = this->controller->curCycle();
  while (!this->incomingStreamDataQueue.empty()) {
    auto &msg = this->incomingStreamDataQueue.front();
    if (msg.readyCycle <= curCycle) {
      this->receiveStreamData(msg.sliceId, msg.dataBlock, msg.storeValueBlock);
      this->incomingStreamDataQueue.pop_front();
    } else {
      break;
    }
  }
}

void LLCStreamEngine::receiveStreamData(const DynamicStreamSliceId &sliceId,
                                        const DataBlock &dataBlock,
                                        const DataBlock &storeValueBlock) {
  /**
   * Since we notify the stream engine for all stream data,
   * it is possible that we don't find the stream if it is not direct
   * stream. Thus we just look up the global map.
   */
  auto dynS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId());
  if (!dynS) {
    // Try stream near-data computing.
    this->ndcController->receiveStreamData(sliceId, dataBlock, storeValueBlock);
    return;
  }
  // Update inflyRequests.
  if (dynS->inflyRequests == 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }
  dynS->inflyRequests--;

  auto S = dynS->getStaticStream();
  bool needIndirect =
      !(dynS->getIndStreams().empty() && dynS->predicatedStreams.empty());
  bool needUpdate = S->isUpdateStream() || S->isAtomicStream();
  bool needSendTo = !(dynS->sendToConfigs.empty());

  LLC_SLICE_DPRINTF(sliceId,
                    "Received StreamData, InflyRequests %d, NeedIndirect %d, "
                    "NeedUpdate %d NeedSendTo %d StoreBlock %s.\n",
                    dynS->inflyRequests, needIndirect, needUpdate, needSendTo,
                    storeValueBlock);

  // Construct all the element data (except for StoreStream).
  if (!S->isStoreComputeStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element = dynS->getElementPanic(idx, "RecvElementData");
      if (element->hasFirstIndirectAtomicReqSeen()) {
        // This is just the second request for IndirectAtomic.
        // No need to extract data.
        continue;
      }
      if (element->isReady()) {
        LLC_SLICE_PANIC(sliceId, "Elements already ready.");
      }
      element->extractElementDataFromSlice(
          dynS->getStaticStream()->getCPUDelegator(), sliceId, dataBlock);
    }
  }

  /**
   * For DirectStream, we should have the slice in our
   * AllocatedSlice.
   */
  LLCStreamSlicePtr slice = nullptr;
  if (!dynS->isIndirect()) {
    slice = this->tryGetSlice(sliceId);
    if (!slice) {
      LLC_SLICE_PANIC(sliceId, "Failed to get slice when receiving "
                               "data for DirectStream.");
    }
    slice->responded(dataBlock, storeValueBlock);
  }

  /**
   * There are many things to do here.
   * 1. Slice - For StoreStream, perform the store and send back Ack.
   * 2. Slice - For SendTo dependence, send the slice to the
   * receiver.
   * 3. Element - Evaluate LoopBoundFunc.
   * 4. Element - Trigger indirect elements if the base is ready (in
   * order).
   * 5. Element - Trigger update operations (out-of-order).
   * 6. Element - Release ready elements in order.
   */

  if (S->isStoreStream()) {
    this->receiveStoreStreamData(dynS, sliceId, storeValueBlock);
  }

  /**
   * Normally we could just send the data to the receiver stream.
   * However, for LoadComputeStream, we should send after the value
   * is computed.
   */
  if (!dynS->sendToConfigs.empty() && !S->isLoadComputeStream()) {
    for (const auto &recvConfig : dynS->sendToConfigs) {
      this->issueStreamDataToLLC(
          dynS, sliceId, dataBlock, recvConfig,
          RubySystem::getBlockSizeBytes() /* PayloadSize */);
    }
  }

  // Evaluate LoopBound.
  dynS->evaluateLoopBound(this);

  if (!dynS->getIndStreams().empty()) {
    for (auto &idxElement : dynS->idxToElementMap) {
      auto &element = idxElement.second;
      LLC_SLICE_DPRINTF(sliceId, "Process for element %llu, Ready %d.\n",
                        element->idx, element->isReady());
      if (element->hasIndirectTriggered()) {
        continue;
      }
      if (!element->isReady()) {
        // Not ready yet. Break.
        break;
      }
      this->triggerIndirectElement(dynS, element);
      element->setIndirectTriggered();
    }
  }

  /**
   * The following logic is only for IndirectStream.
   * For DirectStream, these cases are handled in processSlice().
   */
  if (!dynS->isIndirect()) {
    return;
  }

  if (S->isAtomicComputeStream() || S->isUpdateStream()) {
    this->processAtomicOrUpdateSlice(dynS, sliceId, storeValueBlock);
  }

  if (S->isLoadComputeStream()) {
    /**
     * We register a slice here, directly advance to RESPONDED state,
     * and schedule the computation to merge the code path for
     * DirectStream.
     */
    if (sliceId.getNumElements() != 1) {
      LLC_SLICE_PANIC(sliceId, "IndirectLoadComputeStream with more "
                               "than one element per slice.");
    }
    auto element = dynS->getElementPanic(
        sliceId.getStartIdx(),
        "ReceiveStreamData for IndirectLoadComputeStream");
    auto slice = std::make_shared<LLCStreamSlice>(sliceId);
    slice->allocate(this);
    slice->issue();
    slice->responded(dataBlock, storeValueBlock);
    this->allocatedSlices.push_back(slice);
    element->addSlice(slice);
    this->processLoadComputeSlice(dynS, slice);
  }

  /**
   * Here we release the indirect element, with a few exceptions:
   * 1. DirectStream element released after all slices are released.
   * 2. IndirectStream that will issue after commit, e.g.
   * AtomicStream, will be released when the final request is
   * handled.
   * 3. IndirectLoadComputeStream is released in releaseSlice().
   */
  LLC_S_DPRINTF(dynS->getDynamicStreamId(),
                "[IndirectRelease] Check ShouldIssueAfterCommit %d "
                "IsLoadCompute %d.\n",
                dynS->shouldIssueAfterCommit(), S->isLoadComputeStream());
  if (!dynS->shouldIssueAfterCommit() && !S->isLoadComputeStream()) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      const auto &element = elementIter->second;
      if (!element->areBaseElementsReady()) {
        LLC_ELEMENT_DPRINTF(element,
                            "Cannot release AreBaseElementsReady %d.\n",
                            element->areBaseElementsReady());
        break;
      }
      if (S->isStoreComputeStream()) {
        if (!element->isIndirectStoreAcked()) {
          LLC_ELEMENT_DPRINTF(element,
                              "Cannot release IndirectStore not acked.\n");
          break;
        }
      } else {
        if (!element->isReady()) {
          LLC_ELEMENT_DPRINTF(element, "Cannot release IsReady %d.\n",
                              element->isReady());
          break;
        }
      }
      dynS->eraseElement(elementIter);
    }
  }

  return;
}

void LLCStreamEngine::receiveStoreStreamData(
    LLCDynamicStreamPtr dynS, const DynamicStreamSliceId &sliceId,
    const DataBlock &storeValueBlock) {
  /**
   * We received the response for the StoreStream, we now perform the
   * store. And issue Ack back here if this is DirectStream and no
   * range sync.
   *
   * Although we really should perform the store after the core
   * committed, here I store and only delay sending back the Ack in
   * releaseSlice. So far this only works with DirectStream.
   *
   * This means we still immediately send back StreamAck for:
   * 1. StoreComputeStream without RangeSync.
   * 2. Indirect StoreComputeStream.
   *
   * NOTE: We have to construct the overlap instead of storing the
   * whole line.
   */
  Addr paddr;
  if (!dynS->translateToPAddr(sliceId.vaddr, paddr)) {
    LLC_SLICE_PANIC(sliceId,
                    "Failed to translate StoreStream slice vaddr %#x to paddr.",
                    sliceId.vaddr);
  }
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    assert(dynS->idxToElementMap.count(idx) &&
           "Missing element for StoreStream.");
    auto element = dynS->getElementPanic(idx, "ReceiveStoreStreamData");

    // Compute the overlap and set the data.
    int elementOffset;
    int sliceOffset;
    int overlapSize = element->computeOverlap(sliceId.vaddr, sliceId.getSize(),
                                              sliceOffset, elementOffset);
    auto storeValue = storeValueBlock.getData(sliceOffset, overlapSize);
    LLC_SLICE_DPRINTF_(
        LLCRubyStreamStore, sliceId,
        "StreamStore done with Element %llu, Slice vaddr %#x paddr "
        "%#x, "
        "SliceOffset %d OverlapSize %d Value %s.\n",
        idx, sliceId.vaddr, paddr, sliceOffset, overlapSize,
        GemForgeUtils::dataToString(storeValue, overlapSize));
    this->performStore(paddr + sliceOffset, overlapSize, storeValue);
  }
  if (!dynS->shouldRangeSync() || dynS->isIndirect()) {
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore send back StreamAck.\n");
    if (dynS->isIndirect()) {
      auto element =
          dynS->getElementPanic(sliceId.getStartIdx(), "AckIndirectStore");
      element->setIndirectStoreAcked();
    }
    /**
     * Normally without RangeSync, we would send out one Ack per
     * slice. However, we could just sent this out coarse grained.
     * For simplicity, here I just hack by force some idea ack.
     */
    bool forceIdea = false;
    if (!dynS->isIndirect() && !dynS->shouldRangeSync()) {
      int slicesPerSegment =
          std::max(1, dynS->configData->mlcBufferNumSlices /
                          controller->getMLCStreamBufferToSegmentRatio());
      if ((dynS->streamAckedSlices % slicesPerSegment) != 0) {
        forceIdea = true;
      }
      dynS->streamAckedSlices++;
    }
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

bool LLCStreamEngine::canMigrateStream(LLCDynamicStream *stream) const {
  /**
   * In this implementation, the stream will aggressively
   * migrate to the next element bank, even the credit has only been
   * allocated to the previous element. Therefore, we do not need to
   * check if the next element is allocated.
   */
  auto nextVAddr = stream->peekNextAllocVAddr();
  Addr nextPAddr;
  if (!stream->translateToPAddr(nextVAddr, nextPAddr)) {
    // If the address is faulted, we stay here.
    return false;
  }
  // Check if it is still on this bank.
  if (this->isPAddrHandledByMe(nextPAddr)) {
    // Still here.
    return false;
  }
  if (stream->hasLoopBound() && stream->isLoopBoundBrokenOut()) {
    return false;
  }
  /**
   * We can only enable AdvanceMigrate for DirectStreams.
   * PointerChaseStream can never advance migrate.
   * Streams with LoopBound function can not advance migrate.
   */
  if (!this->controller->isStreamAdvanceMigrateEnabled() ||
      stream->isPointerChase() || stream->hasLoopBound()) {
    if ((stream->hasIndirectDependent() || stream->isPointerChase() ||
         stream->hasLoopBound()) &&
        stream->inflyRequests > 0) {
      // We are still waiting data for indirect usages:
      // 1. Indirect streams.
      // 2. Update request.
      // 3. Pointer chasing.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for inflyRequests %llu.\n",
                    stream->inflyRequests);
      return false;
    }
    if (stream->hasIndirectElementReadyToIssue()) {
      // We are still waiting for some indirect streams to be issued.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for readyIndirectElements %llu.\n",
                    stream->getNumIndirectElementReadyToIssue());
      return false;
    }
    /**
     * ! A hack to delay migrate if there is
     * waitingPredicatedElements for any ! indirect stream.
     */
    for (auto IS : stream->getIndStreams()) {
      if (!IS->waitingPredicatedElements.empty()) {
        return false;
      }
      if (IS->getStaticStream()->isReduction() ||
          IS->getStaticStream()->isPointerChaseIndVar()) {
        // We wait for the reduction element to be done.
        if (!IS->idxToElementMap.empty()) {
          const auto &element = IS->idxToElementMap.begin()->second;
          /**
           * ! Due to the current hack implementation, an element may
           * already be ! allocated for the next bank. Our way to
           * hack this is check if the ! base is already ready. If
           * not, then they are for next ! bank.
           */
          if (!element->isReady()) {
            for (const auto &baseE : element->baseElements) {
              if (baseE->dynStreamId == stream->getDynamicStreamId()) {
                if (baseE->isReady()) {
                  // The base element is ready, which means this is
                  // from this bank. If it's not ready, then we
                  // should have inflyRequest.
                  LLC_S_DPRINTF(IS->getDynamicStreamId(),
                                "Delayed migration for reduction "
                                "for idx %llu.\n",
                                element->idx);
                  return false;
                }
              }
            }
          }
        }
      }
    }
  }
  return true;
}

void LLCStreamEngine::wakeup() {

  // Sanity check.
  if (this->streams.size() >= 1000) {
    panic("Too many LLCStream.\n");
  }

  if (this->streams.size() > 0) {
    this->controller->m_statLLCNumDirectStreams.sample(this->streams.size());
  }
  if (!this->readyComputations.empty()) {
    this->controller->m_statLLCNumReadyComputations.sample(
        this->readyComputations.size());
  }
  if (!this->inflyComputations.empty()) {
    this->controller->m_statLLCNumInflyComputations.sample(
        this->inflyComputations.size());
  }

  // Drain incoming element data.
  this->drainIncomingStreamDataMsg();

  this->processStreamFlowControlMsg();
  this->issueStreams();
  this->issueStreamRangesToMLC();
  this->findMigratingStreams();
  this->migrateStreams();
  this->startComputation();
  this->completeComputation();
  this->processSlices();
  this->commitController->commit();

  // So we limit the issue rate in issueStreams.
  while (!this->requestQueue.empty()) {
    const auto &req = this->requestQueue.front();
    if (!req.translationDone) {
      break;
    }
    this->issueStreamRequestToRemoteBank(req);
    this->requestQueue.pop_front();
  }

  if (!this->streams.empty() || !this->migratingStreams.empty() ||
      !this->requestQueue.empty() || !this->incomingStreamDataQueue.empty() ||
      !this->allocatedSlices.empty() || !this->readyComputations.empty() ||
      !this->inflyComputations.empty() ||
      this->commitController->hasStreamToCommit()) {
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::initializeTranslationBuffer() {
  if (!this->translationBuffer) {
    this->translationBuffer =
        m5::make_unique<StreamTranslationBuffer<RequestQueueIter>>(
            this->controller->getCPUDelegator()->getDataTLB(),
            [this](PacketPtr pkt, ThreadContext *tc, RequestQueueIter reqIter)
                -> void { this->translationCallback(pkt, tc, reqIter); },
            true /* AccessLastLevelTLBOnly */
        );
  }
}

bool LLCStreamEngine::canMergeAsMulticast(LLCDynamicStreamPtr dynSA,
                                          LLCDynamicStreamPtr dynSB) const {
  /**
   * Streams are considered possible to merged into one multicast
   * stream iff:
   * 1. They are from cores within the same multicast group.
   * 2. They both have linear address generation function.
   * 3. They have same dynamic parameters for address generation.
   * 4. They have the same request type.
   */
  const auto &dynSAId = dynSA->getDynamicStreamId();
  const auto &dynSBId = dynSB->getDynamicStreamId();
  if (dynSAId.coreId == dynSBId.coreId) {
    // Ignore streams from the same core.
    return false;
  }
  if (dynSA->getStaticStream()->isAtomicComputeStream() ||
      dynSB->getStaticStream()->isAtomicComputeStream()) {
    // Should never multicast atomic streams.
    return false;
  }
  auto multicastGroupIdA =
      this->controller->getMulticastGroupId(dynSAId.coreId);
  auto multicastGroupIdB =
      this->controller->getMulticastGroupId(dynSBId.coreId);
  if (multicastGroupIdA != multicastGroupIdB) {
    // They are not from the same multicast group.
    return false;
  }
  if (dynSA->getStaticId() != dynSA->getStaticId()) {
    return false;
  }
  auto linearAddrGenA = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSA->configData->addrGenCallback);
  auto linearAddrGenB = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSB->configData->addrGenCallback);
  if (!linearAddrGenA || !linearAddrGenB) {
    return false;
  }
  const auto &formalParamsA = dynSA->configData->addrGenFormalParams;
  const auto &formalParamsB = dynSB->configData->addrGenFormalParams;
  if (formalParamsA.size() != formalParamsB.size()) {
    return false;
  }
  for (auto i = 0; i < formalParamsA.size(); ++i) {
    const auto &paramA = formalParamsA.at(i);
    const auto &paramB = formalParamsB.at(i);
    if (!paramA.isInvariant || !paramB.isInvariant) {
      // One of the parameters rely on stream.
      return false;
    }
    if (paramA.invariant != paramB.invariant) {
      return false;
    }
  }
  if (this->getDirectStreamReqType(dynSA) !=
      this->getDirectStreamReqType(dynSB)) {
    return false;
  }
  return true;
}

void LLCStreamEngine::addStreamToMulticastTable(LLCDynamicStreamPtr dynS) {
  bool hasIndirectDependent = dynS->hasIndirectDependent();
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "Add to MulticastTable, HasIndirectDependent %d "
                 "DepEdges %d.\n",
                 hasIndirectDependent, dynS->configData->depEdges.size());
  /**
   * Currently we do not try to multicast streams with indirect
   * dependence. This includes streams with SendTo dependence.
   */
  // We only try to merge into multicast if it has no indirect
  // dependent.
  if (!hasIndirectDependent && dynS->configData->depEdges.empty()) {
    for (auto &entry : this->multicastStreamMap) {
      auto dynSRoot = entry.first;
      auto &group = entry.second;
      auto canMerge = this->canMergeAsMulticast(dynS, dynSRoot);
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynamicStreamId(),
                     "Check CanMergeAsMulticast %d.\n", canMerge);
      if (canMerge) {
        // Found the entry.
        group.push_back(dynS);
        dynS->setMulticastGroupLeader(dynSRoot);
        this->sortMulticastGroup(group);
        LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynamicStreamId(),
                       "Merged into MulticastGroup.\n");
        return;
      }
    }
  }
  // Not found.
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "New MulticastGroup.\n");
  this->multicastStreamMap
      .emplace(std::piecewise_construct, std::forward_as_tuple(dynS),
               std::forward_as_tuple())
      .first->second.push_back(dynS);
  dynS->setMulticastGroupLeader(dynS);
}

void LLCStreamEngine::removeStreamFromMulticastTable(LLCDynamicStreamPtr dynS) {
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "Remove from MulticastTable.\n");
  auto multicastGroupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(multicastGroupLeader);
  assert(mapIter != this->multicastStreamMap.end() &&
         "Failed to find multicast group.");
  // First we remove dynS from this group.
  auto &group = mapIter->second;
  bool erased = false;
  for (auto iter = group.begin(), end = group.end(); iter != end; ++iter) {
    if ((*iter) == dynS) {
      group.erase(iter);
      erased = true;
      break;
    }
  }
  assert(erased && "Failed to erase from MulticastGroup.");
  // Clear the multicast leader for dynS.
  dynS->setMulticastGroupLeader(nullptr);
  if (mapIter->first == dynS) {
    if (!group.empty()) {
      // If this is the leader and the group is not empty after
      // removing, we reinsert this group with a new leader.
      auto newLeader = group.front();
      for (auto &S : group) {
        S->setMulticastGroupLeader(newLeader);
      }
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, newLeader->getDynamicStreamId(),
                     "Select as NewLeader.\n");
      this->multicastStreamMap.emplace(newLeader, group);
    }
    // We can remove the group from the table now.
    assert(this->multicastStreamMap.erase(dynS) == 1 &&
           "Failed to remove the group");
  }
}

bool LLCStreamEngine::hasMergedAsMulticast(LLCDynamicStreamPtr dynS) const {
  return this->getMulticastGroup(dynS).size() > 1;
}

LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynamicStreamPtr dynS) {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

const LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynamicStreamPtr dynS) const {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

bool LLCStreamEngine::canIssueByMulticastPolicy(
    LLCDynamicStreamPtr dynS) const {
  /**
   * There are some policies to tune if we want to delay a stream
   * from issuing to have more multicast oppotunties. Here are the
   * policies:
   * ----- Most Relaxed (Optimize for Latency) ------
   * - Do nothing. Always return ture.
   * - The first stream with NextSliceAllocated in the
   * MulticastGroup.
   * - The stream must be the first one in the MulticastGroup.
   * ---- Most Constranit (Optimize for Traffic) ----
   */

  const auto &group = this->getMulticastGroup(dynS);

  const auto policy = this->controller->getStreamMulticastIssuePolicy();
  switch (policy) {
  case AbstractStreamAwareController::MulticastIssuePolicy::Any:
    return true;
  case AbstractStreamAwareController::MulticastIssuePolicy::FirstAllocated:
    for (const auto &S : group) {
      if (!S->isNextSliceCredited()) {
        continue;
      }
      // This is the first available stream.
      return S == dynS;
    }
    // Should never happen.
    assert(false && "DynS not found in MulticastGroup.");
  case AbstractStreamAwareController::MulticastIssuePolicy::First:
    return group.front() == dynS;
  default:
    return true;
  }
}

void LLCStreamEngine::sortMulticastGroup(StreamVec &group) const {
  auto comparator = [this](const LLCDynamicStreamPtr &SA,
                           const LLCDynamicStreamPtr &SB) -> bool {
    auto sliceIdxA = SA->getNextAllocSliceIdx();
    auto sliceIdxB = SB->getNextAllocSliceIdx();
    if (sliceIdxA != sliceIdxB) {
      return sliceIdxA < sliceIdxB;
    }
    /**
     * When the next sliceId is the same, it's interesting how we
     * break the tie.
     * 1. If we considered streams with next slice not allocated
     * "smaller", we are more frequently blocked and this achieves
     * maximum save of the traffic, as it exposes more multicast
     * opportunity.
     * 2. Otherwise, we try to issue ready streams with smaller
     * sliceId as soon as possible. This reduces the multicast
     * opportunity, but may help the latency.
     */
    if (SA->isNextSliceCredited() != SB->isNextSliceCredited()) {
      return !SA->isNextSliceCredited(); // Option 1
      // return SA->isNextSliceCredited(); // Option 2
    }
    // Break the tie with core id.
    return SA->getDynamicStreamId().coreId < SB->getDynamicStreamId().coreId;
  };
  std::sort(group.begin(), group.end(), comparator);
  if (Debug::LLCRubyStreamMulticast) {
    DPRINTF(LLCRubyStreamMulticast, "Sorted MulticastGroup:---\n");
    for (auto &dynS : group) {
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                     "NextAllocSliceIdx %lu, Allocated %d.\n",
                     dynS->getNextAllocSliceIdx(), dynS->isNextSliceCredited());
    }
    DPRINTF(LLCRubyStreamMulticast, "---\n");
  }
}

void LLCStreamEngine::generateMulticastRequest(RequestQueueIter reqIter,
                                               LLCDynamicStreamPtr targetDynS) {
  assert(this->controller->isStreamMulticastEnabled());
  auto &group = this->getMulticastGroup(targetDynS);

  const auto &targetSliceId = reqIter->sliceId;
  auto targetSliceIdx = targetDynS->getNextAllocSliceIdx();
  assert(targetSliceIdx > 0 &&
         "DynS should have positive NextSliceIdx as it generated "
         "reqIter.");
  LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, targetSliceId,
                     "Generate MulticastRequest.\n");
  // Start to scan, skip dynS.
  for (auto idx = 0; idx < group.size(); ++idx) {
    auto dynS = group.at(idx);
    if (dynS == targetDynS) {
      // We just issued.
      continue;
    }
    if (!dynS->isNextSliceCredited()) {
      // Not allocated, skip this one.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 < targetSliceIdx) {
      // This is behind stream, skip it.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 > targetSliceIdx) {
      // This is future stream, we are done.
      break;
    }
    // Found a multicast stream candidate.
    auto slice = this->allocateSlice(dynS);
    slice->issue();
    const auto &sliceId = slice->getSliceId();
    // Sanity check for multicast slices.
    if (sliceId.vaddr != targetSliceId.vaddr) {
      LLC_SLICE_PANIC(sliceId, "Mismatch VAddr %#x for Multicast Slice %#x.",
                      sliceId.vaddr, targetSliceId.vaddr);
    }
    if (sliceId.getSize() != targetSliceId.getSize()) {
      LLC_SLICE_PANIC(sliceId, "Mismatch Size %d for Multicast Slice %d.",
                      sliceId.getSize(), targetSliceId.getSize());
    }

    auto SS = dynS->getStaticStream();
    SS->statistic.numLLCIssueSlice++;

    // Add this to the request.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType != reqIter->requestType) {
      LLC_SLICE_PANIC(sliceId,
                      "Mismatch RequestType for Multicast Slice, "
                      "Target %s, Ours %s.",
                      reqIter->requestType, reqType);
    }
    if (reqType == CoherenceRequestType_GETU) {
      SS->statistic.numLLCSentSlice++;
      SS->se->numLLCSentSlice++;
      SS->statistic.numLLCMulticastSlice++;
      SS->statistic.numLLCCanMulticastSlice++;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast Issue.\n");
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    if (hasIndirectDependent) {
      LLC_SLICE_PANIC(sliceId, "Multicast Issue with IndirectDependent.\n");
    }
    dynS->prevIssuedCycle = this->controller->curCycle();
    dynS->updateIssueClearCycle();
    // Track infly requests.
    dynS->inflyRequests++;

    reqIter->multicastSliceIds.push_back(sliceId);
  }

  if (!reqIter->multicastSliceIds.empty()) {
    targetDynS->getStaticStream()->statistic.numLLCMulticastSlice++;
  }

  // Finally we want to make sure we are sorted.
  this->sortMulticastGroup(group);
}

void LLCStreamEngine::processStreamFlowControlMsg() {
  auto iter = this->pendingStreamFlowControlMsgs.begin();
  auto end = this->pendingStreamFlowControlMsgs.end();
  while (iter != end) {
    const auto &msg = *iter;
    bool processed = false;
    for (auto stream : this->streams) {
      if (stream->getDynamicStreamId() == msg.getDynStreamId() &&
          msg.getStartIdx() == stream->creditedSliceIdx) {
        // We found it.
        // Update the idx.
        LLC_S_DPRINTF(stream->getDynamicStreamId(), "Add credit %lu -> %lu.\n",
                      msg.getStartIdx(), msg.getEndIdx());
        stream->addCredit(msg.getNumElements());
        // Maybe we want to resort the Multicast group.
        if (this->controller->isStreamMulticastEnabled() &&
            this->hasMergedAsMulticast(stream)) {
          this->sortMulticastGroup(this->getMulticastGroup(stream));
        }
        processed = true;
        break;
      }
    }
    if (!processed) {
      // Delete the credit message if the stream is already released
      // due to StreamLoopBound.
      if (!LLCDynamicStream::getLLCStream(msg.getDynStreamId())) {
        LLC_S_DPRINTF(msg.getDynStreamId(),
                      "[Credit] Discard credit %lu -> %lu as LLCDynStream "
                      "already released.\n",
                      msg.getStartIdx(), msg.getEndIdx());
        processed = true;
      }
    }
    if (processed) {
      iter = this->pendingStreamFlowControlMsgs.erase(iter);
    } else {
      // LLCSE_DPRINTF("Failed to process stream credit %s [%lu,
      // %lu).\n",
      //               msg.streamId.name.c_str(), msg.getStartIdx(),
      //               msg.getEndIdx());
      ++iter;
    }
  }
}

void LLCStreamEngine::issueStreams() {

  /**
   * Enforce thresholds for issue stream requests here.
   * 1. If there are many requests in the queue, there is no need to
   * inject more packets to block the queue.
   * 2. As a sanity check, we limit the total number of infly direct
   * requests.
   */

  if (this->streamIssueMsgBuffer->getSize(this->controller->clockEdge()) >=
      this->maxInqueueRequests) {
    return;
  }

  // By cheching i < nStreams we avoid issuing the same stream more
  // than once.
  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  for (int i = 0, issuedStreams = 0, nStreams = this->streams.size();
       i < nStreams && issuedStreams < this->issueWidth; ++i) {
    auto curStream = streamIter;
    // Move to the next one.
    ++streamIter;
    auto readyS = this->findStreamReadyToIssue(*curStream);
    if (readyS) {
      if (readyS->isIndirect()) {
        this->issueStreamIndirect(readyS);
      } else {
        this->issueStreamDirect(readyS);
      }
      issuedStreams++;
      // Push the stream back to the end.
      this->streams.splice(streamEnd, this->streams, curStream);
    }
  }
}

LLCDynamicStreamPtr
LLCStreamEngine::findStreamReadyToIssue(LLCDynamicStreamPtr dynS) {

  auto S = dynS->getStaticStream();
  auto &statistic = S->statistic;
  statistic.sampleLLCAliveElements(dynS->idxToElementMap.size());
  statistic.sampleLLCInflyComputation(dynS->incompleteComputations);
  /**
   * Prioritize indirect streams.
   */
  LLCDynamicStreamPtr readyS = this->findIndirectStreamReadyToIssue(dynS);
  if (readyS) {
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::IndirectPriority);
    return readyS;
  }

  if (!dynS->isNextSliceCredited()) {
    // LLC_S_DPRINTF_(LLCRubyStreamNotIssue,
    // dynS->getDynamicStreamId(),
    //                "Not issue: NextSliceNotAllocated.\n");
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::NextSliceNotAllocated);
    return nullptr;
  }

  if (dynS->isNextSliceOverflown()) {
    // Do not try to issue this slice if it is overflown.
    LLC_S_DPRINTF(dynS->getDynamicStreamId(),
                  "Not issue: NextSliceOverflown.\n");
    return nullptr;
  }

  /**
   * If we enabled Multicast and this is not the lowest stream in
   * the multicast group, i.e. lagging the most behind, then we do
   * not issue it as we are waiting for behind streams to catch up
   * and explore multicast opportunity.
   */
  if (this->controller->isStreamMulticastEnabled()) {
    if (!this->canIssueByMulticastPolicy(dynS)) {
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MulticastPolicy);
      return nullptr;
    }
  }

  /**
   * Check if we have reached issue limit for this stream. Only do
   * this for streams with core user.
   */
  const auto curCycle = this->controller->curCycle();
  if (dynS->shouldUpdateIssueClearCycle()) {
    if (curCycle < dynS->prevIssuedCycle + dynS->issueClearCycle) {
      // We can not issue yet.
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynamicStreamId(),
                     "Not issue: IssueClearCycle %s Current %s.\n",
                     dynS->issueClearCycle, curCycle - dynS->prevIssuedCycle);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::IssueClearCycle);
      return nullptr;
    }
  }

  /**
   * Enforce the per stream maxInflyRequests constraint.
   * PointerChaseStream always has at most one infly request.
   */
  if (dynS->inflyRequests == dynS->getMaxInflyRequests()) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynamicStreamId(),
                   "Not issue: MaxInflyRequests %d.\n",
                   dynS->getMaxInflyRequests());
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
    return nullptr;
  }

  /**
   * Allocate the element on Atomic and StoreStream.
   * Additional check on StoreStream, which should have StoreValue
   * ready.
   */
  if (S->isStoreComputeStream() || S->isAtomicComputeStream()) {
    auto nextSlice = dynS->getNextAllocSlice();
    if (!nextSlice) {
      LLC_S_PANIC(dynS->getDynamicStreamId(),
                  "Failed to get next alloc slice.");
    }
    const auto &nextSliceId = nextSlice->getSliceId();
    if (S->isStoreComputeStream()) {
      /**
       * Schedule computation and check if StoreValue of this slice
       * is ready.
       */
      for (auto iter = dynS->idxToElementMap.find(nextSliceId.getStartIdx()),
                end = dynS->idxToElementMap.end();
           iter != end; ++iter) {
        auto &element = iter->second;
        Addr paddr;
        assert(dynS->translateToPAddr(element->vaddr, paddr) &&
               "Failed to translate for DirectStoreComputeStream.");
        if (!this->isPAddrHandledByMe(paddr)) {
          // This element is not handled here.
          break;
        }
        if (!element->isReady()) {
          if (!element->areBaseElementsReady() ||
              dynS->incompleteComputations >=
                  this->controller->myParams
                      ->llc_stream_engine_max_infly_computation) {
            // In order issue with maximum number incomplete
            // computations equals to the LLC SE throughput.
            break;
          }
          if (element->areBaseElementsReady() &&
              !element->isComputationScheduled()) {
            this->pushReadyComputation(element);
          }
        }
      }
      for (auto idx = nextSliceId.getStartIdx(); idx < nextSliceId.getEndIdx();
           ++idx) {
        auto element = dynS->getElementPanic(idx, "Check StoreValue Ready.");
        // Simply schedule the computation.
        if (!element->isReady()) {
          if (element->areBaseElementsReady() &&
              !element->isComputationScheduled()) {
            this->pushReadyComputation(element);
          }
          LLC_SLICE_DPRINTF(nextSliceId,
                            "StoreValue from element %llu not "
                            "ready, delay issuing.\n",
                            idx);
          if (!element->areBaseElementsReady()) {
            statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::BaseValueNotReady);
          } else {
            statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::ValueNotReady);
          }
          return nullptr;
        }
      }
    }
  }

  /**
   * Check that the next address is still handled here.
   * Due to the waiting indirect element, a stream may not be
   * migrated immediately after the stream engine found the next
   * element is not handled here. In such case, we simply give up and
   * return false.
   *
   * In case of faulting, the slice will be skipped (see
   * issueDirectStream()).
   */
  Addr vaddr = dynS->peekNextAllocVAddr();
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {
    if (!this->isPAddrHandledByMe(paddr)) {
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::PendingMigrate);
      return nullptr;
    }
  }

  // We should be able to issue this stream.
  statistic.sampleLLCStreamEngineIssueReason(
      StreamStatistic::LLCStreamEngineIssueReason::Issued);
  return dynS;
}

LLCDynamicStreamPtr
LLCStreamEngine::findIndirectStreamReadyToIssue(LLCDynamicStreamPtr dynS) {

  if (!dynS->hasIndirectElementReadyToIssue()) {
    return nullptr;
  }

  // Find the indirect stream with lowest element index.
  LLCDynamicStreamPtr readyS = nullptr;
  uint64_t readyElementIdx = 0;
  for (auto dynIS : dynS->getAllIndStreams()) {
    auto IS = dynIS->getStaticStream();
    IS->statistic.sampleLLCAliveElements(dynIS->idxToElementMap.size());
    // Enforce the per stream maxInflyRequests constraint.
    if (dynIS->inflyRequests == dynIS->getMaxInflyRequests()) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynIS->getDynamicStreamId(),
                     "[NotIssue] MaxInflyRequests %d.\n",
                     dynIS->getMaxInflyRequests());
      IS->statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
      continue;
    }

    if (auto element = dynIS->getFirstReadyToIssueElement()) {
      auto elementIdx = element->idx;

      /**
       * Hack: We enforce ordering of alised IndirectUpdateStream
       * here.
       * TODO: Really implement the ordering scheme by piggyback the
       * previous element going to that bank and let the indrect LLC
       * SE handles ordering. However, delay issuing here actually
       * pays more overhead, so we should be okay as we are not
       * cheating for performance.
       */
      if (IS->isUpdateStream()) {
        bool hasAliasedWithPreviousElement = false;
        for (const auto &idxElement : dynIS->idxToElementMap) {
          if (idxElement.first >= elementIdx) {
            break;
          }
          const auto &prevElement = idxElement.second;
          if (prevElement->vaddr == element->vaddr &&
              !prevElement->isComputedValueReady()) {
            LLC_ELEMENT_DPRINTF(element,
                                "[NotIssue] Aliased Indirect "
                                "UpdateElement %llu %#x.\n",
                                prevElement->idx, prevElement->vaddr);
            IS->statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::
                    AliasedIndirectUpdate);
            hasAliasedWithPreviousElement = true;
            break;
          }
        }
        if (hasAliasedWithPreviousElement) {
          continue;
        }
      }

      if (!readyS || readyElementIdx > elementIdx) {
        readyS = dynIS;
        readyElementIdx = elementIdx;
      }
    }
  }

  return readyS;
}

void LLCStreamEngine::issueStreamDirect(LLCDynamicStream *dynS) {

  auto S = dynS->getStaticStream();
  auto &statistic = S->statistic;

  // Get the next address.
  auto slice = this->allocateSlice(dynS);
  const auto &sliceId = slice->getSliceId();
  Addr vaddr = sliceId.vaddr;
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {

    // The paddr is valid. We issue request to the LLC.
    Addr vaddrLine = makeLineAddress(vaddr);
    Addr paddrLine = makeLineAddress(paddr);

    // Remember that the slice has issued.
    slice->issue();

    if (!this->isPAddrHandledByMe(paddr)) {
      LLC_S_PANIC(dynS->getDynamicStreamId(),
                  "Next address is not handled here %#x.", paddr);
    }

    statistic.numLLCIssueSlice++;

    // Push to the request queue.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType == CoherenceRequestType_GETU) {
      statistic.numLLCSentSlice++;
      S->se->numLLCSentSlice++;
      if (this->hasMergedAsMulticast(dynS)) {
        statistic.numLLCCanMulticastSlice++;
      }
    }
    auto requestIter =
        this->enqueueRequest(S->getCPUDelegator(), sliceId, vaddrLine,
                             paddrLine, this->myMachineType(), reqType);

    if (S->isStoreStream()) {
      /**
       * For StoreStream, we build the stored data by extracting
       * overlap region from elements. Notice that we can release any
       * older elements, as later we perform the store in slice
       * granularity, not element granularity. Thus element is not
       * used anymore.
       */
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        assert(dynS->idxToElementMap.count(idx) &&
               "Missing element for StoreStream.");
        const auto &element = dynS->idxToElementMap.at(idx);
        assert(element->isReady() && "StoreElement is not ready.");

        // Compute the overlap and set the data.
        int elementOffset;
        int sliceOffset;
        int overlapSize = element->computeOverlap(
            sliceId.vaddr, sliceId.getSize(), sliceOffset, elementOffset);
        requestIter->dataBlock.setData(element->getUInt8Ptr(elementOffset),
                                       sliceOffset, overlapSize);
        requestIter->storeSize = overlapSize;
        LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                           "Get StoreValue from element %llu, line [%#x, +%d), "
                           "elementOffset %#x.\n",
                           element->idx, sliceId.vaddr + sliceOffset,
                           overlapSize, elementOffset);
      }
    }

    // Check if we track inflyRequests.
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    dynS->inflyRequests++;
    LLC_SLICE_DPRINTF(sliceId, "Issue, InflyRequests + 1 = %d.\n",
                      dynS->inflyRequests);
    /**
     * Try to handle multicast for streams:
     * 1. Has multicast group.
     * 2. No indirect dependent (can be relaxed later).
     */
    if (!hasIndirectDependent && this->controller->isStreamMulticastEnabled()) {
      this->generateMulticastRequest(requestIter, dynS);
    }

  } else {

    /**
     * ! The paddr is not valid. We ignore this slice.
     */
    LLC_SLICE_DPRINTF(sliceId, "Discard due to fault.\n");
    slice->faulted();

    if (!dynS->getIndStreams().empty()) {
      // Unless this is PtrChaseIV stream.
      if (dynS->isPointerChase()) {
      } else {
        LLC_SLICE_PANIC(sliceId, "Faulted at %#x with Indirect Streams.",
                        sliceId.vaddr);
      }
    }
    statistic.numLLCFaultSlice++;
  }

  // This is also considered issued.
  dynS->prevIssuedCycle = this->controller->curCycle();
  dynS->updateIssueClearCycle();
}

CoherenceRequestType
LLCStreamEngine::getDirectStreamReqType(LLCDynamicStream *stream) const {
  auto reqType = CoherenceRequestType_GETH;
  auto SS = stream->getStaticStream();
  switch (SS->getStreamType()) {
  case ::LLVM::TDG::StreamInfo_Type_AT:
  case ::LLVM::TDG::StreamInfo_Type_ST:
    reqType = CoherenceRequestType_STREAM_STORE;
    break;
  case ::LLVM::TDG::StreamInfo_Type_LD: {
    if (SS->isUpdateStream()) {
      reqType = CoherenceRequestType_STREAM_STORE;
    } else if (SS->isLoadComputeStream()) {
      // LoadComputeStream sends back the computed value.
      reqType = CoherenceRequestType_GETH;
    } else {
      if (auto dynS = SS->getDynamicStream(stream->getDynamicStreamId())) {
        if (dynS->shouldCoreSEIssue()) {
          // We have to send back the data.
          reqType = CoherenceRequestType_GETU;
        }
      } else {
        // The dynamic stream is already released, we don't really
        // care.
      }
    }
    break;
  }
  default:
    panic("Invalid offloaded stream type.\n");
  }
  return reqType;
}

void LLCStreamEngine::issueStreamIndirect(LLCDynamicStream *dynIS) {

  auto element = dynIS->getFirstReadyToIssueElement();
  if (!element) {
    LLC_S_PANIC(dynIS->getDynamicStreamId(),
                "Try to issue, but no ready element.");
  }
  auto elementIdx = element->idx;
  if (dynIS->shouldIssueBeforeCommit()) {
    // We delay issuing this after committed.
    this->generateIndirectStreamRequest(dynIS, element);
  } else {
    LLC_S_DPRINTF(dynIS->getDynamicStreamId(),
                  "Delay Issuing for AfterCommit element %llu\n.", elementIdx);
  }
  // Don't forget to the element issued.
  dynIS->markElementIssued(elementIdx);
}

void LLCStreamEngine::generateIndirectStreamRequest(
    LLCDynamicStream *dynIS, LLCStreamElementPtr element) {

  auto IS = dynIS->getStaticStream();
  if (IS->isReduction() || IS->isPointerChaseIndVar()) {
    LLC_S_PANIC(dynIS->getDynamicStreamId(),
                "Reduction is no longer handled here.");
    return;
  }

  if (IS->isStoreComputeStream() || IS->isAtomicComputeStream()) {
    this->issueIndirectStoreOrAtomicRequest(dynIS, element);
    return;
  }

  /**
   * Finally normal indirect load stream.
   */
  this->issueIndirectLoadRequest(dynIS, element);
  return;
}

void LLCStreamEngine::issueIndirectLoadRequest(LLCDynamicStream *dynIS,
                                               LLCStreamElementPtr element) {
  /**
   * This function handles the most basic case: IndirectLoadStream.
   */
  auto elementIdx = element->idx;
  DynamicStreamSliceId sliceId;
  sliceId.getDynStreamId() = dynIS->getDynamicStreamId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticStream();
  auto dynCoreIS = IS->getDynamicStream(dynIS->getDynamicStreamId());

  auto reqType = CoherenceRequestType_GETH;
  if (dynCoreIS && dynCoreIS->shouldCoreSEIssue()) {
    /**
     * For LoadComputeStream, we issue GETH and send back the compute
     * result. For UpdateStream, we issue GETH and send back the old
     * value.
     */
    if (!IS->isLoadComputeStream() && !IS->isUpdateStream()) {
      reqType = CoherenceRequestType_GETU;
    }
  }
  LLC_SLICE_DPRINTF(sliceId,
                    "Issue IndirectLoad InflyReq %d %s VAddr %#x CoreDynS %d "
                    "ShouldCoreSEIssue %d IsLoadCompute %d.\n",
                    dynIS->inflyRequests,
                    CoherenceRequestType_to_string(reqType), elementVAddr,
                    dynCoreIS != nullptr,
                    dynCoreIS ? dynCoreIS->shouldCoreSEIssue() : -1,
                    IS->isLoadComputeStream());

  assert(!dynIS->isPseudoOffload() &&
         "Indirect stream should never be PseudoOffload.");
  auto totalSliceSize = 0;
  auto totalSlices = 0;
  while (totalSliceSize < elementSize) {
    Addr curSliceVAddr = elementVAddr + totalSliceSize;
    // Make sure the slice is contained within one line.
    int lineOffset = curSliceVAddr % blockBytes;
    auto curSliceSize = std::min(elementSize - totalSliceSize,
                                 static_cast<int>(blockBytes) - lineOffset);
    // Here we set the slice vaddr and size.
    sliceId.vaddr = curSliceVAddr;
    sliceId.size = curSliceSize;
    Addr curSlicePAddr;
    if (dynIS->translateToPAddr(curSliceVAddr, curSlicePAddr)) {
      Addr curSliceVAddrLine = makeLineAddress(curSliceVAddr);
      Addr curSlicePAddrLine = makeLineAddress(curSlicePAddr);
      IS->statistic.numLLCIssueSlice++;
      if (reqType == CoherenceRequestType_GETU) {
        IS->statistic.numLLCSentSlice++;
        IS->se->numLLCSentSlice++;
      }

      // Push to the request queue.
      this->enqueueRequest(IS->getCPUDelegator(), sliceId, curSliceVAddrLine,
                           curSlicePAddrLine, this->myMachineType(), reqType);
      dynIS->inflyRequests++;
    } else {
      // For faulted slices, we simply ignore it.
      LLC_SLICE_DPRINTF(sliceId, "Discard due to fault, vaddr %#x.\n",
                        sliceId.vaddr);
      dynIS->getStaticStream()->statistic.numLLCFaultSlice++;
    }

    totalSliceSize += curSliceSize;
    totalSlices++;
  }

  if (IS->isLoadComputeStream() && totalSlices != 1) {
    LLC_S_PANIC(dynIS->getDynamicStreamId(),
                "IndirectLoadComputeStream with Multi-Line Element "
                "is not supported.");
  }
}

void LLCStreamEngine::issueIndirectStoreOrAtomicRequest(
    LLCDynamicStream *dynIS, LLCStreamElementPtr element) {

  auto elementIdx = element->idx;
  DynamicStreamSliceId sliceId;
  sliceId.getDynStreamId() = dynIS->getDynamicStreamId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;
  LLC_SLICE_DPRINTF(sliceId, "Issue IndirectStore/Atomic VAddr %#x.\n",
                    elementVAddr);

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticStream();
  const auto &indirectConfig = dynIS->configData;

  // This is a store/atomic, we need to issue STREAM_STORE request.
  assert(elementSize <= sizeof(uint64_t) && "Oversized merged store stream.");
  if (dynIS->hasTotalTripCount()) {
    assert(elementIdx < dynIS->getTotalTripCount() &&
           "Try to store beyond TotalTripCount.");
  }

  int lineOffset = elementVAddr % blockBytes;
  assert(lineOffset + elementSize <= blockBytes &&
         "Multi-line merged store stream.");

  sliceId.vaddr = elementVAddr;
  sliceId.size = elementSize;
  Addr elementPAddr;
  if (dynIS->translateToPAddr(elementVAddr, elementPAddr)) {
    IS->statistic.numLLCIssueSlice++;
    auto vaddrLine = makeLineAddress(elementVAddr);
    auto paddrLine = makeLineAddress(elementPAddr);
    /**
     * Compute the store value.
     * If this is a MergededPedicatedStream, it is a constant value.
     * If this is a MergededLoadStoreDepStream, it is computed use
     * the StoreCallback.
     * TODO: These should be merged together.
     */
    uint64_t storeValue = 0;
    if (IS->isMergedPredicated()) {
      // TODO: This is no longer supported.
      panic("MergedPredicated is not supported for now.");
      // storeValue = indirectConfig->constUpdateValue;
    } else if (IS->isMergedLoadStoreDepStream()) {
      // Compute the value.
      auto getBaseStreamValue =
          [&element](uint64_t baseStreamId) -> StreamValue {
        return element->getBaseStreamValue(baseStreamId);
      };
      auto params = convertFormalParamToParam(indirectConfig->storeFormalParams,
                                              getBaseStreamValue);
      storeValue = indirectConfig->storeCallback->invoke(params).front();
    } else {
      assert("Unknow merged stream type.");
    }

    // Push to the request queue.
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore -> RequestQueue, StoreValue %lu.\n",
                       storeValue);
    bool isIdeaStore = false;
    int storeSize = sliceId.size;
    if (this->controller->isStreamIdeaStoreEnabled()) {
      isIdeaStore = true;
    } else if (this->controller->isStreamCompactStoreEnabled()) {
      /**
       * Check if we can compact.
       * This is just an approximation, as the request is sending
       * out immediately.
       * TODO: Implement a realistic compact scheme.
       */
      if (dynIS->prevStorePAddrLine == paddrLine) {
        // We can compact.
        isIdeaStore = true;
      } else {
        // As an overhead, we set StoreSize to 64 due to compaction.
        if (IS->isDirectMemStream()) {
          storeSize = RubySystem::getBlockSizeBytes();
        }
      }
    }

    dynIS->prevStorePAddrLine = paddrLine;
    dynIS->prevStoreCycle = this->controller->curCycle();
    if (isIdeaStore) {
      this->performStore(elementPAddr, elementSize,
                         reinterpret_cast<uint8_t *>(&storeValue));
      LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                         "Ideal StreamStore done with value %llu, "
                         "send back StreamAck.\n",
                         storeValue);

      const bool forceIdeaAck = true;
      this->issueStreamAckToMLC(sliceId, forceIdeaAck);
      if (!this->requestQueue.empty()) {
        this->scheduleEvent(Cycles(1));
      }
    } else {
      auto reqIter = this->enqueueRequest(
          IS->getCPUDelegator(), sliceId, vaddrLine, paddrLine,
          this->myMachineType(), CoherenceRequestType_STREAM_STORE);
      dynIS->inflyRequests++;
      auto lineOffset = sliceId.vaddr % RubySystem::getBlockSizeBytes();
      reqIter->dataBlock.setData(reinterpret_cast<uint8_t *>(&storeValue),
                                 lineOffset, sliceId.size);
      reqIter->storeSize = storeSize;
    }

  } else {
    panic("Faulted merged store stream.");
  }
}

LLCStreamEngine::RequestQueueIter LLCStreamEngine::enqueueRequest(
    GemForgeCPUDelegator *cpuDelegator, const DynamicStreamSliceId &sliceId,
    Addr vaddrLine, Addr paddrLine, MachineType destMachineType,
    CoherenceRequestType type) {
  this->requestQueue.emplace_back(sliceId, paddrLine, destMachineType, type);
  auto requestQueueIter = std::prev(this->requestQueue.end());
  // To match with TLB interface, we first create a fake packet.
  auto tc = cpuDelegator->getSingleThreadContext();
  RequestPtr req = std::make_shared<Request>(paddrLine, sliceId.getSize(), 0,
                                             cpuDelegator->dataMasterId());
  // Set the vaddrLine as this is what we want to translate.
  req->setVirt(vaddrLine);
  // Simply always read request, since this is a fake request.
  auto pkt = Packet::createRead(req);
  // Do not allocate data for this fake packet.
  uint8_t *pktData = nullptr;
  pkt->dataStatic(pktData);
  // Start the translation.
  LLC_SLICE_DPRINTF(sliceId, "Enqueue %s Req: Start Translation.\n",
                    CoherenceRequestType_to_string(type));
  this->translationBuffer->addTranslation(pkt, tc, requestQueueIter);
  // Since this generates a request, we schedule a wakeup.
  this->scheduleEvent(Cycles(1));
  return requestQueueIter;
}

void LLCStreamEngine::translationCallback(PacketPtr pkt, ThreadContext *tc,
                                          RequestQueueIter reqIter) {
  assert(!reqIter->translationDone && "Translation already done.");
  reqIter->translationDone = true;
  LLC_SLICE_DPRINTF(reqIter->sliceId, "Translated %s Req.\n",
                    CoherenceRequestType_to_string(reqIter->requestType));
  // Remember to release the pkt.
  delete pkt;
}

void LLCStreamEngine::issueStreamRequestToRemoteBank(
    const LLCStreamRequest &req) {
  const auto &sliceId = req.sliceId;
  const auto paddrLine = req.paddrLine;
  auto selfMachineId = this->controller->getMachineID();

  auto destMachineType = req.destMachineType;
  if (destMachineType != MachineType::MachineType_L2Cache &&
      destMachineType != MachineType::MachineType_Directory) {
    LLC_SLICE_PANIC(sliceId, "Issue to Unsupported MachineType %s.\n",
                    destMachineType);
  }

  auto destMachineId = selfMachineId;
  bool handledHere = (destMachineType == selfMachineId.getType()) &&
                     this->isPAddrHandledByMe(req.paddrLine);
  if (handledHere) {
    LLC_SLICE_DPRINTF(sliceId,
                      "Issue [local] %s request vaddr %#x paddrLine %#x value "
                      "%s.\n",
                      req.requestType, sliceId.vaddr, paddrLine, req.dataBlock);
  } else {
    destMachineId =
        this->controller->mapAddressToLLCOrMem(paddrLine, destMachineType);
    LLC_SLICE_DPRINTF(
        sliceId,
        "Issue [remote] %s request to %s paddr %#x inqueue %d buffered %d "
        "value %s.\n",
        req.requestType, destMachineId, paddrLine,
        this->streamIndirectIssueMsgBuffer->getSize(curTick()),
        this->indReqBuffer->getTotalBufferedRequests(), req.dataBlock);
  }

  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = req.requestType;
  msg->m_XXNewRewquestor.add(MachineID(MachineType::MachineType_L1Cache,
                                       sliceId.getDynStreamId().coreId));
  msg->m_Destination.add(destMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_sliceIds.add(sliceId);

  // We need to set hold the store value.
  if (req.requestType == CoherenceRequestType_STREAM_STORE) {
    msg->m_streamStoreBlk = req.dataBlock;
    if (req.storeSize > 8) {
      // We model this as a whole cache line put back.
      msg->m_MessageSize = MessageSizeType_Response_Data;
    }
  } else if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
    msg->m_DataBlk = req.dataBlock;
    msg->m_sendToStreamId = req.forwardToStreamId;
    /**
     * We model special size for StreamForward request.
     */
    msg->m_MessageSize = this->controller->getMessageSizeType(req.payloadSize);
  }

  if (Debug::LLCRubyStreamMulticast && !req.multicastSliceIds.empty()) {
    std::stringstream ss;
    for (const auto &multicastSliceId : req.multicastSliceIds) {
      auto mlcMachineID =
          MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                    multicastSliceId.getDynStreamId().coreId);
      ss << ' ' << mlcMachineID;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast to %s.\n",
                       ss.str());
  }

  for (const auto &multicastSliceId : req.multicastSliceIds) {
    // TODO: We should really also pass on the sliceId.
    auto mlcMachineID =
        MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                  multicastSliceId.getDynStreamId().coreId);
    msg->m_XXNewRewquestor.add(mlcMachineID);
    msg->m_sliceIds.add(multicastSliceId);
  }

  if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
    auto dynS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId());
    if (dynS) {
      auto totalNodesBeforeLLC =
          MachineType_base_number(MachineType::MachineType_L2Cache);
      dynS->getStaticStream()->statistic.sampleLLCSendTo(
          selfMachineId.getRawNodeID() - totalNodesBeforeLLC,
          destMachineId.getRawNodeID() - totalNodesBeforeLLC);
    }
  }

  if (handledHere) {
    // Quick path for StreamForward to myself.
    if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
      this->receiveStreamForwardRequest(*msg);
      return;
    }
    /**
     * Quick path for the second request to release an indirect
     * atomic.
     */
    if (this->tryToProcessIndirectAtomicUnlockReq(*msg)) {
      return;
    }
    Cycles latency(1);
    this->streamIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  } else {
    /**
     * Issue to StreamRequestBuffer to enforce
     * MaxInqueueRequestPerStream.
     */
    this->indReqBuffer->pushRequest(msg);
    // Cycles latency(1);
    // this->streamIndirectIssueMsgBuffer->enqueue(
    //     msg, this->controller->clockEdge(),
    //     this->controller->cyclesToTicks(latency));
  }
}

LLCStreamEngine::ResponseMsgPtr LLCStreamEngine::createStreamMsgToMLC(
    const DynamicStreamSliceId &sliceId, CoherenceResponseType type,
    Addr paddrLine, const uint8_t *data, int dataSize, int payloadSize,
    int lineOffset) {
  auto selfMachineId = this->controller->getMachineID();
  MachineID mlcMachineId(MachineType::MachineType_L1Cache,
                         sliceId.getDynStreamId().coreId);

  auto msg = std::make_shared<ResponseMsg>(this->controller->clockEdge());
  // For StreamAck, we do not care about the address?
  msg->m_addr = paddrLine;
  msg->m_Type = type;
  msg->m_Sender = selfMachineId;
  msg->m_Destination.add(mlcMachineId);
  msg->m_MessageSize = MessageSizeType_Response_Control;
  msg->m_sliceIds.add(sliceId);
  // Try to copy data.
  if (data) {
    assert(lineOffset + dataSize <= RubySystem::getBlockSizeBytes());
    msg->m_DataBlk.setData(data, lineOffset, dataSize);
    msg->m_MessageSize = this->controller->getMessageSizeType(payloadSize);
  }
  return msg;
}

void LLCStreamEngine::issueStreamMsgToMLC(ResponseMsgPtr msg, bool forceIdea) {

  auto mlcMachineId = msg->m_Destination.singleElement();
  const auto &sliceId = msg->m_sliceIds.singleSliceId();

  if (this->controller->isStreamIdeaAckEnabled() || forceIdea) {
    auto mlcController =
        AbstractStreamAwareController::getController(mlcMachineId);
    auto mlcSE = mlcController->getMLCStreamEngine();
    // StreamAck is also disguised as StreamData.
    mlcSE->receiveStreamData(*msg);
    LLC_SLICE_DPRINTF(sliceId, "Send ideal %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  } else {
    /**
     * This should match with LLC controller l2_response_latency.
     * TODO: Really get this value from the controller.
     */
    Cycles latency(2);
    this->streamResponseMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
    LLC_SLICE_DPRINTF(sliceId, "Send %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  }
}

void LLCStreamEngine::issueStreamAckToMLC(const DynamicStreamSliceId &sliceId,
                                          bool forceIdea) {

  // For StreamAck, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_ACK, paddrLine, nullptr, 0, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDoneToMLC(const DynamicStreamSliceId &sliceId,
                                           bool forceIdea) {

  // For StreamDone, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_DONE, paddrLine, nullptr, 0, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamRangesToMLC() {
  if (!this->controller->isStreamRangeSyncEnabled()) {
    return;
  }
  for (auto stream : this->streams) {
    auto &rangeBuilder = stream->getRangeBuilder();
    if (!rangeBuilder->hasReadyRanges()) {
      continue;
    }
    auto range = rangeBuilder->popReadyRange();
    /**
     * For DirectStream without IndirectStreams, we issue
     * immediately, as the MLC should really be the one creating this
     * range.
     */
    bool isDirectRange = !stream->isIndirect() &&
                         stream->getIndStreams().empty() &&
                         !stream->isPointerChase();
    LLC_SE_DPRINTF_(StreamRangeSync, "Issue %s range to MLC: %s.\n",
                    isDirectRange ? "direct" : "mixed", *range);
    this->issueStreamRangeToMLC(range, isDirectRange);
  }
}

void LLCStreamEngine::issueStreamRangeToMLC(DynamicStreamAddressRangePtr &range,
                                            bool forceIdea) {
  // Create a fake paddr and slice id.
  Addr paddrLine = 0;
  DynamicStreamSliceId sliceId;
  sliceId.elementRange = range->elementRange;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_RANGE, paddrLine, nullptr, 0, 0, 0);
  msg->m_range = range;
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToMLC(const DynamicStreamSliceId &sliceId,
                                           Addr paddrLine, const uint8_t *data,
                                           int dataSize, int payloadSize,
                                           int lineOffset, bool forceIdea) {
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_DATA_EXCLUSIVE, paddrLine, data, dataSize,
      payloadSize, lineOffset);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToLLC(
    LLCDynamicStreamPtr stream, const DynamicStreamSliceId &sliceId,
    const DataBlock &dataBlock, const CacheStreamConfigureDataPtr &recvConfig,
    int payloadSize) {
  /**
   * Unlike sending data to MLC, we have to calculate the virtual
   * address of the receiving stream and translate that. Also, we can
   * only handle the simpliest case so far: no spliting, and no
   * multi-line receiver element.
   */
  auto elementIdx = sliceId.getStartIdx();
  auto recvElementVAddr =
      recvConfig->addrGenCallback
          ->genAddr(elementIdx, recvConfig->addrGenFormalParams,
                    getStreamValueFail)
          .front();
  auto recvElementVAddrEnd = recvElementVAddr + recvConfig->elementSize;
  // Check that receiver does not across lines.
  for (auto idx = sliceId.getStartIdx() + 1; idx < sliceId.getEndIdx(); ++idx) {
    auto vaddr =
        recvConfig->addrGenCallback
            ->genAddr(idx, recvConfig->addrGenFormalParams, getStreamValueFail)
            .front();
    auto vaddrEnd = vaddr + recvConfig->elementSize;
    recvElementVAddr = std::min(recvElementVAddr, vaddr);
    recvElementVAddrEnd = std::max(recvElementVAddrEnd, vaddrEnd);
  }
  auto recvElementVAddrLine = makeLineAddress(recvElementVAddr);
  auto recvElementVAddrEndLine = makeLineAddress(recvElementVAddr);
  if (recvElementVAddrLine != recvElementVAddrEndLine) {
    LLC_SLICE_PANIC(sliceId, "Multiline StreamForward Receiver: %s.",
                    recvConfig->dynamicId);
  }
  Addr recvElementPAddrLine;
  if (stream->translateToPAddr(recvElementVAddrLine, recvElementPAddrLine)) {
    // Now we enqueue the translation request.
    auto reqIter = this->enqueueRequest(
        recvConfig->stream->getCPUDelegator(), sliceId, recvElementVAddrLine,
        recvElementPAddrLine, recvConfig->offloadedMachineType,
        CoherenceRequestType_STREAM_FORWARD);
    // Remember the receiver dynamic id and forwarded data block.
    reqIter->forwardToStreamId = recvConfig->dynamicId;
    reqIter->dataBlock = dataBlock;
    reqIter->payloadSize = payloadSize;
  } else {
    LLC_SLICE_PANIC(sliceId, "Translation fault on the ReceiverStream: %s.",
                    recvConfig->dynamicId);
  }
}

void LLCStreamEngine::sendOffloadedLoopBoundRetToMLC(LLCDynamicStreamPtr stream,
                                                     uint64_t totalTripCount,
                                                     Addr brokenPAddr) {
  auto mlcSE = stream->getMLCController()->getMLCStreamEngine();
  assert(mlcSE && "Missing MLC SE.");
  mlcSE->receiveStreamTotalTripCount(stream->getDynamicStreamId(),
                                     totalTripCount, brokenPAddr);
}

void LLCStreamEngine::findMigratingStreams() {
  // Scan all streams for migration target.
  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  while (streamIter != streamEnd) {
    auto stream = *streamIter;
    if (this->canMigrateStream(stream)) {
      this->migratingStreams.emplace_back(stream);
      streamIter = this->streams.erase(streamIter);
    } else {
      ++streamIter;
    }
  }
}

void LLCStreamEngine::migrateStreams() {
  auto streamIter = this->migratingStreams.begin();
  auto streamEnd = this->migratingStreams.end();
  int migrated = 0;
  /**
   * We limit the number of inqueue migrating streams.
   */
  while (streamIter != streamEnd && migrated < this->migrateWidth &&
         this->streamMigrateMsgBuffer->getSize(curTick()) < 2) {
    auto stream = *streamIter;
    assert(this->canMigrateStream(stream) && "Can't migrate stream.");
    /**
     * Check the migrate controller.
     */
    auto nextVAddr = stream->peekNextAllocVAddr();
    Addr nextPAddr;
    if (!stream->translateToPAddr(nextVAddr, nextPAddr)) {
      LLC_S_PANIC(stream->getDynamicStreamId(), "Fault on migrating stream.");
    }
    auto nextMachineId = this->controller->mapAddressToLLCOrMem(
        makeLineAddress(nextPAddr), this->controller->getMachineID().getType());
    if (!this->migrateController->canMigrateTo(stream, nextMachineId)) {
      ++streamIter;
      continue;
    }
    this->migrateStream(stream);
    this->migrateController->startMigrateTo(stream, nextMachineId);
    streamIter = this->migratingStreams.erase(streamIter);
    migrated++;
  }
}

void LLCStreamEngine::migrateStream(LLCDynamicStream *stream) {

  // Create the migrate request.
  Addr vaddr = stream->peekNextAllocVAddr();
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Migrating streams should have valid paddr.");
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddrLine, selfMachineId.type);

  LLC_S_DPRINTF(stream->getDynamicStreamId(),
                "Migrate to LLC%d, InflyReq %d AdvancedMigration %d IndirectS "
                "%d. Remain DirectStreams %llu.\n",
                addrMachineId.num, stream->inflyRequests,
                this->controller->isStreamAdvanceMigrateEnabled(),
                stream->getIndStreams().size(), this->streams.size());

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  msg->m_MessageSize = MessageSizeType_Data;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  this->removeStreamFromMulticastTable(stream);

  stream->migratingStart();
}

void LLCStreamEngine::migrateStreamCommit(LLCDynamicStream *stream,
                                          Addr paddr) {
  // Create the migrate request.
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddrLine, selfMachineId.type);

  LLC_S_DPRINTF_(StreamRangeSync, stream->getDynamicStreamId(),
                 "[Commit] Migrate to LLC%d.\n", addrMachineId.num);

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  // Migrating CommitHead is just a control message.
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_IsCommit = true;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));
}

MachineID LLCStreamEngine::mapPaddrToSameLevelBank(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddr, selfMachineId.type);
  return addrMachineId;
}

bool LLCStreamEngine::isPAddrHandledByMe(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddr, selfMachineId.getType());
  return addrMachineId == selfMachineId;
}

void LLCStreamEngine::print(std::ostream &out) const {}

void LLCStreamEngine::receiveStreamIndirectRequest(const RequestMsg &req) {

  this->initializeTranslationBuffer();

  // Simply copy and inject the msg to L1 request in.
  const auto &sliceId = req.m_sliceIds.singleSliceId();
  assert(sliceId.isValid() && "Invalid stream slice for indirect request.");

  LLC_SLICE_DPRINTF(sliceId,
                    "Receive [indirect] %s request paddrLine %#x delay cycle "
                    "%s.\n",
                    CoherenceRequestType_to_string(req.m_Type), req.m_addr,
                    this->controller->curCycle() -
                        this->controller->ticksToCycles(req.getTime()));

  if (req.m_Type == CoherenceRequestType_STREAM_FORWARD) {
    // Quick path for stream forwarding.
    this->receiveStreamForwardRequest(req);
    return;
  }

  if (this->tryToProcessIndirectAtomicUnlockReq(req)) {
    // Quick path for the second request to release an indirect
    // atomic.
    return;
  }

  auto msg = std::make_shared<RequestMsg>(req);
  Cycles latency(1);
  this->streamIssueMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                      this->controller->cyclesToTicks(latency));
}

void LLCStreamEngine::receiveStreamForwardRequest(const RequestMsg &req) {
  this->processStreamForwardRequest(req);
}

void LLCStreamEngine::processStreamForwardRequest(const RequestMsg &req) {

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  const auto &recvDynId = req.m_sendToStreamId;
  // Search through the direct streams.
  auto dynS = LLCDynamicStream::getLLCStream(recvDynId);
  if (!dynS) {
    // Failed to find the stream (may be terminated). Try NDC.
    this->ndcController->receiveStreamForwardRequest(req);
    LLC_SLICE_DPRINTF(sliceId, "Cannot find the direct receiver: %s.\n",
                      recvDynId);
    return;
  }
  /**
   * Sample the LLC forward latency.
   */
  auto sendCycle = this->controller->ticksToCycles(req.getTime());
  auto latency = this->controller->curCycle() - sendCycle;
  LLC_SLICE_DPRINTF(sliceId, "[Forward] Received. Latency %llu.\n", latency);
  if (auto sender = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId())) {
    sender->getStaticStream()->statistic.llcForwardLat.sample(latency);
  }

  /**
   * Normally we search for the receiver in myself and my indirect
   * stream. However, there is a special case: I am the sender! This
   * is used so far to implement IndirectReductionS that dependent
   * both on the BackBaseIndirectS and BackBaseDirectS:
   *
   * BaseBaseDirectS -> BackBaseIndirectS -> IndirectReductionS.
   *  |                                              |
   *  ----------------------->>>---------------------
   *
   * In such case, we only search in my Two-Level IndirectS...
   */
  bool foundReceiver = false;
  if (sliceId.getDynStreamId() != dynS->getDynamicStreamId()) {
    // Search for receiver in myself and my indirect streams.
    if (dynS->isBasedOn(sliceId.getDynStreamId())) {
      foundReceiver = true;
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        dynS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
      }
    }

    for (auto dynIS : dynS->getIndStreams()) {
      if (dynIS->isBasedOn(sliceId.getDynStreamId())) {
        foundReceiver = true;
        for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
             ++idx) {
          dynIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
        }
      }
    }
  } else {
    // Sender is myself. Search for Two-Level Indirection.
    for (auto dynIS : dynS->getIndStreams()) {
      for (auto dynIIS : dynIS->getIndStreams()) {
        if (dynIIS->isBasedOn(sliceId.getDynStreamId())) {
          foundReceiver = true;
          for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
               ++idx) {
            dynIIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
          }
        }
      }
    }
  }
  if (!foundReceiver) {
    LLC_SLICE_PANIC(sliceId, "Cannot find the receiver: %s.", recvDynId);
  }
}

bool LLCStreamEngine::tryToProcessIndirectAtomicUnlockReq(
    const RequestMsg &req) {
  if (req.m_sliceIds.sliceIds.size() != 1 ||
      req.m_Type != CoherenceRequestType_STREAM_STORE) {
    // Not single slice id or store request.
    return false;
  }
  const auto &sliceId = req.m_sliceIds.singleSliceId();
  auto dynS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId());
  if (!dynS) {
    // Failed to find the DynamicStream.
    return false;
  }
  auto S = dynS->getStaticStream();
  if (S->isAtomicComputeStream() && dynS->isIndirect() &&
      dynS->shouldIssueBeforeCommit() && dynS->shouldIssueAfterCommit()) {
    auto elementIdx = sliceId.getStartIdx();
    assert(sliceId.getNumElements() == 1 &&
           "Multi-Element slice for IndirectAtomicStream.");
    auto element =
        dynS->getElementPanic(elementIdx, "receiveStreamIndirectRequest");
    if (element->hasFirstIndirectAtomicReqSeen()) {
      /**
       * This is the second request to unlock the line of indirect
       * atomic. We just send back the Ack.
       */
      // Update inflyRequests.
      if (dynS->inflyRequests == 0) {
        LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
      }
      dynS->inflyRequests--;

      LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                         "[Commit] Atomic released. Remaining Elements %llu.\n",
                         dynS->idxToElementMap.size());
      Addr elementPAddr;
      assert(dynS->translateToPAddr(element->vaddr, elementPAddr) &&
             "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
      auto elementMemSize = dynS->getMemElementSize();
      if (this->controller->isStreamAtomicLockEnabled()) {
        /**
         * For now we just delay the Ack until the line is unlocked.
         */
        this->atomicLockManager->commit(elementPAddr, elementMemSize, element,
                                        true /* shouldAckAfterUnlock */,
                                        sliceId);
      } else {
        /**
         * Ideal case: Immediately send back Ack.
         */
        this->atomicLockManager->commit(elementPAddr, elementMemSize, element,
                                        false /* shouldAckAfterUnlock */,
                                        sliceId);
        this->issueStreamAckToMLC(sliceId);
      }

      /**
       * No matter what, we should release elements that are
       * unlocked.
       */
      element->setSecondIndirectAtomicReqSeen();
      while (!dynS->idxToElementMap.empty()) {
        auto elementIter = dynS->idxToElementMap.begin();
        const auto &element = elementIter->second;
        if (!element->isReady() || !element->areBaseElementsReady() ||
            !element->hasSecondIndirectAtomicReqSeen()) {
          break;
        }
        dynS->eraseElement(elementIter);
      }
      return true;
    }
  }
  return false;
}

void LLCStreamEngine::triggerIndirectElement(LLCDynamicStreamPtr stream,
                                             LLCStreamElementPtr element) {
  if (stream->getIndStreams().empty() && stream->predicatedStreams.empty()) {
    // There is no stream dependent on my data.
    return;
  }

  auto idx = element->idx;
  assert(element->isReady());

  // First we handle any indirect element.
  for (auto IS : stream->getIndStreams()) {

    /**
     * If the indirect stream is behind one iteration, base element
     * of iteration i should trigger the indirect element of
     * iteration i + 1. Also we should be careful to not overflow the
     * boundary.
     */
    auto indirectElementIdx = idx;
    if (IS->isOneIterationBehind()) {
      indirectElementIdx = idx + 1;
    }
    if (IS->hasTotalTripCount() &&
        indirectElementIdx > IS->getTotalTripCount()) {
      // Ignore overflow elements.
      LLC_ELEMENT_DPRINTF(element,
                          "[TriggerInd] Skip IS %s TotalTripCount "
                          "%lld < ElemIdx %llu.\n",
                          IS->getDynamicStreamId(), IS->getTotalTripCount(),
                          indirectElementIdx);
      continue;
    }

    // We should have the element.
    if (!IS->idxToElementMap.count(indirectElementIdx)) {
      LLC_S_PANIC(IS->getDynamicStreamId(), "Missing IndirectElement %llu.",
                  indirectElementIdx);
    }

    auto &indirectElement = IS->idxToElementMap.at(indirectElementIdx);

    /**
     * Check if the stream has predication.
     */
    assert(!IS->isPredicated() && "Disable predication for now.");
    // Not predicated, add to readyElements.
    if (stream->baseStream) {
      // The only type of two-level indirection is
      // Reduction/StoreCompute.
      auto ISS = IS->getStaticStream();
      if (!ISS->isReduction() && !ISS->isStoreComputeStream()) {
        LLC_S_PANIC(IS->getDynamicStreamId(),
                    "Does not support Two-Level Indirection other than "
                    "Reduction/StoreCompute.");
      }
    }
    LLC_S_DPRINTF(IS->getDynamicStreamId(),
                  "Check if element %llu BaseElementsReady %d.\n",
                  indirectElement->idx,
                  indirectElement->areBaseElementsReady());
    if (indirectElement->areBaseElementsReady()) {
      if (IS->getStaticStream()->isReduction() ||
          IS->getStaticStream()->isPointerChaseIndVar()) {
        // Reduction now is handled as computation.
        this->pushReadyComputation(indirectElement);
      } else {
        IS->markElementReadyToIssue(indirectElementIdx);
      }
    } else {
      for (const auto &baseE : indirectElement->baseElements) {
        LLC_S_DPRINTF(IS->getDynamicStreamId(),
                      "BaseElements Ready %d %s %llu.\n", baseE->isReady(),
                      baseE->dynStreamId, baseE->idx);
      }
    }
  }

  assert(!stream->configData->predCallback && "Disable predication for now.");
  assert(stream->waitingPredicatedElements.empty() &&
         "No predCallback for predicated elements.");
}

void LLCStreamEngine::triggerUpdate(LLCDynamicStreamPtr dynS,
                                    LLCStreamElementPtr element,
                                    const DynamicStreamSliceId &sliceId,
                                    const DataBlock &storeValueBlock,
                                    DataBlock &loadValueBlock,
                                    uint32_t &payloadSize) {

  auto S = dynS->getStaticStream();

  // Perform the operation.
  auto elementMemSize = S->getMemElementSize();
  auto elementCoreSize = S->getCoreElementSize();
  assert(elementCoreSize <= elementMemSize &&
         "CoreElementSize should not exceed MemElementSize.");
  auto elementVAddr = element->vaddr;

  Addr elementPAddr;
  assert(dynS->translateToPAddr(elementVAddr, elementPAddr) &&
         "Fault on vaddr of UpdateStream.");
  const auto lineSize = RubySystem::getBlockSizeBytes();

  /**
   * This is an update stream, and we have to handle multi-line
   * elements.
   * 1. Compute the store value if this is the first time, and
   * directly stores all the result.
   * 2. Send back the overlapped old value.
   * TODO: Really schedule the computation to model the latency.
   * TODO: Reload the value here to avoid aliased update stream.
   * TODO: Multi-Line Update should really be careful.
   */
  if (!element->isComputedValueReady()) {
    auto getStreamValue = [&element](uint64_t streamId) -> StreamValue {
      return element->getBaseOrMyStreamValue(streamId);
    };
    auto params = convertFormalParamToParam(dynS->configData->storeFormalParams,
                                            getStreamValue);
    auto storeValue = dynS->configData->storeCallback->invoke(params);

    /**
     * ! For now just record the stats.
     */
    auto numMicroOps = S->getComputationNumMicroOps();
    // For now we don't bother add the stats to the core in my bank.
    S->recordComputationInCoreStats();
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);

    element->setComputedValue(storeValue);
    assert(elementMemSize <= sizeof(storeValue) &&
           "UpdateStream size overflow.");
    for (int storedSize = 0; storedSize < elementMemSize;) {
      Addr vaddr = elementVAddr + storedSize;
      Addr paddr;
      if (!dynS->translateToPAddr(vaddr, paddr)) {
        LLC_ELEMENT_PANIC(element, "Fault on vaddr of UpdateStream.");
      }
      auto lineOffset = vaddr % lineSize;
      auto size = elementMemSize - storedSize;
      if (lineOffset + size > lineSize) {
        size = lineSize - lineOffset;
      }
      this->performStore(paddr, size, storeValue.uint8Ptr(storedSize));
      storedSize += size;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUpdate done with value %s.\n", storeValue);
  }

  /**
   * Send back the overlap value within this line.
   */
  Addr loadBlockVAddrLine = makeLineAddress(sliceId.vaddr);
  int elementOffset = 0;
  int loadBlockOffset = 0;
  auto overlapSize = element->computeOverlap(loadBlockVAddrLine, lineSize,
                                             loadBlockOffset, elementOffset);
  loadValueBlock.setData(element->getUInt8Ptr(elementOffset), loadBlockOffset,
                         overlapSize);
  payloadSize = overlapSize;
}

void LLCStreamEngine::triggerAtomic(LLCDynamicStreamPtr dynS,
                                    LLCStreamElementPtr element,
                                    const DynamicStreamSliceId &sliceId,
                                    const DataBlock &storeValueBlock,
                                    DataBlock &loadValueBlock,
                                    uint32_t &payloadSize) {

  auto S = dynS->getStaticStream();

  // Perform the operation.
  auto elementMemSize = S->getMemElementSize();
  auto elementCoreSize = S->getCoreElementSize();
  assert(elementCoreSize <= elementMemSize &&
         "CoreElementSize should not exceed MemElementSize.");
  auto elementVAddr = element->vaddr;

  // Create a single slice for this element.
  DynamicStreamSliceId elementSliceId;
  elementSliceId.getDynStreamId() = dynS->getDynamicStreamId();
  elementSliceId.getStartIdx() = element->idx;
  elementSliceId.getEndIdx() = element->idx + 1;

  Addr elementPAddr;
  assert(dynS->translateToPAddr(elementVAddr, elementPAddr) &&
         "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
  auto lineOffset = elementVAddr % RubySystem::getBlockSizeBytes();
  if (lineOffset + elementMemSize > RubySystem::getBlockSizeBytes()) {
    LLC_ELEMENT_PANIC(element, "Multi-Line AtomicElement.");
  }

  // Very limited AtomicRMW support.
  auto atomicRet =
      this->performStreamAtomicOp(dynS, element, elementPAddr, elementSliceId);
  auto loadedValue = atomicRet.first;
  bool memoryModified = atomicRet.second;
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Perform StreamAtomic, RetValue %llu.\n", loadedValue);
  loadValueBlock.setData(reinterpret_cast<uint8_t *>(&loadedValue), lineOffset,
                         elementCoreSize);
  payloadSize = elementCoreSize;
  if (element->hasFirstIndirectAtomicReqSeen()) {
    LLC_ELEMENT_PANIC(element, "Perform atomic operation more than once.");
  }
  element->setFirstIndirectAtomicReqSeen();
  this->atomicLockManager->enqueue(elementPAddr, elementMemSize, element,
                                   memoryModified);
  if (!(dynS->shouldIssueBeforeCommit() && dynS->shouldIssueAfterCommit())) {
    // This AtomicStream just takes one request, we can immediately
    // commit it.
    this->atomicLockManager->commit(elementPAddr, elementMemSize, element);
  }
}

LLCStreamSlicePtr LLCStreamEngine::allocateSlice(LLCDynamicStreamPtr dynS) {
  auto slice = dynS->allocNextSlice(this);
  this->allocatedSlices.push_back(slice);
  return slice;
}

LLCStreamSlicePtr
LLCStreamEngine::tryGetSlice(const DynamicStreamSliceId &sliceId) {
  for (auto &slice : this->allocatedSlices) {
    const auto &id = slice->getSliceId();
    /**
     * We have additional check for the vaddr in case for multi-line
     * elements.
     */
    if (id == sliceId && id.vaddr == sliceId.vaddr) {
      return slice;
    }
  }
  return nullptr;
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::releaseSlice(SliceList::iterator sliceIter) {
  const auto &slice = *sliceIter;
  LLC_SLICE_DPRINTF(slice->getSliceId(), "Released.\n");
  slice->released();
  const auto &sliceId = slice->getSliceId();
  if (auto dynS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId())) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      auto &element = elementIter->second;
      // StoreComputeStream is never ready.
      if ((element->isReady() ||
           dynS->getStaticStream()->isStoreComputeStream()) &&
          element->areSlicesReleased()) {
        if (!element->areBaseElementsReady()) {
          LLC_ELEMENT_PANIC(
              element, "Released when Ready %d ValueBaseReady %d Slices %d.",
              element->isReady(), element->areBaseElementsReady(),
              element->getNumSlices());
        }
        /**
         * We avoid releasing the element if it is the only two left
         * in idxToElementMap and it is known not the last one. This
         * is to avoid a bug when there are multi-line elements, the
         * next slice is not initialized yet, thus the element has
         * not seen all the slices and may falsely return true for
         * areSlicesReleased().
         * TODO: Handle this multi-line elements more elegantly.
         */
        if (dynS->idxToElementMap.size() > 2 ||
            (dynS->hasTotalTripCount() &&
             element->idx + 2 >= dynS->getTotalTripCount())) {
          dynS->eraseElement(elementIter);
          continue;
        }
      }
      break;
    }
  }
  return this->allocatedSlices.erase(sliceIter);
}

void LLCStreamEngine::processSlices() {
  auto iter = this->allocatedSlices.begin();
  auto end = this->allocatedSlices.end();
  while (iter != end) {
    iter = this->processSlice(iter);
  }
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::processSlice(SliceList::iterator sliceIter) {
  auto &slice = *sliceIter;
  auto dynS =
      LLCDynamicStream::getLLCStream(slice->getSliceId().getDynStreamId());
  if (!dynS) {
    // Jesus, the LLCStream is already released.
    switch (slice->getState()) {
    default:
      LLC_SLICE_PANIC(slice->getSliceId(),
                      "LLCStream released, but slice not.");
    case LLCStreamSlice::State::ALLOCATED:
    case LLCStreamSlice::State::RESPONDED:
    case LLCStreamSlice::State::FAULTED:
      return this->releaseSlice(sliceIter);
    case LLCStreamSlice::State::ISSUED:
      // We are still waiting for the response.
      return ++sliceIter;
    }
  }
  switch (slice->getState()) {
  default:
    LLC_SLICE_PANIC(slice->getSliceId(), "Invalid state.");
  case LLCStreamSlice::State::ALLOCATED:
  case LLCStreamSlice::State::ISSUED:
    // We are still waiting for the response.
    return ++sliceIter;
  case LLCStreamSlice::State::FAULTED:
    return this->releaseSlice(sliceIter);
  case LLCStreamSlice::State::RESPONDED:
    break;
  }
  /**
   * The slice is already responded, see if we can process it.
   * So far we need to process the slice for these two cases:
   * 1. AtomicComputeStream/UpdateStream.
   * This is where the write request is generated, and is done after
   * all elements are committed in the core (if RangeSync enabled).
   * 2. LoadComputeStream.
   * This is where we schedule the computation for LoadComputeStream,
   * and send back the result to core if core needs the value. This
   * does not need to wait for committment.
   */

  const auto &sliceId = slice->getSliceId();
  auto S = dynS->getStaticStream();
  /**
   * For LoadComputeStream, we schedule computation if the element is
   * value ready. If all element's LoadComputeValue is ready, we send
   * back to core. Also, we have to wait until the LoadComputeValue
   * sent back to core before releasing the slice.
   */
  if (S->isLoadComputeStream()) {
    this->processLoadComputeSlice(dynS, slice);
    if (!slice->isLoadComputeValueSent()) {
      return ++sliceIter;
    }
  }
  /**
   * If this stream require RangeSync, we have to check that all
   * elements are committed in the core. One exception is for
   * IndirectLoadComputeStream, which we should release immediately.
   */
  if (dynS->shouldRangeSync() &&
      !(S->isLoadComputeStream() && dynS->isIndirect())) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElementPanic(idx, "Check element committed for update.");
      if (!element->hasCoreCommitted()) {
        // We are still waiting for the core to commit.
        return ++sliceIter;
      }
    }
  }
  if (S->isAtomicComputeStream() || S->isUpdateStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElementPanic(idx, "Check base elements ready for update.");
      // LLC_SLICE_DPRINTF(
      //     sliceId, "Process for element %llu, Ready %d, BaseReady
      //     %d.\n", element->idx, element->isReady(),
      //     element->areBaseElementsReady());
      if (!element->areBaseElementsReady()) {
        // We are still waiting for base elements.
        return ++sliceIter;
      }
      /**
       * Update slice also require the element to be ready.
       * Although this has responded, a multi-slice element may still
       * not be ready.
       */
      if (S->isUpdateStream() && !element->isReady()) {
        LLC_ELEMENT_DPRINTF(element, "[Update] Slice blocked by me.\n");
        return ++sliceIter;
      }
    }
    // We can finally process it.
    this->processAtomicOrUpdateSlice(dynS, sliceId, slice->getStoreBlock());
  }

  /**
   * We are done with this slice.
   * If this is a StoreStream with RangeSync, we send back the Ack
   * here. NOTE: For DirectStoreComputeStream with RangeSync, the
   * StreamDone message really completes the whole workflow. For
   * simplicity, here we send back Ack ideally.
   */
  if (dynS->shouldRangeSync() && S->isStoreComputeStream()) {
    bool forceIdea = false;
    if (!dynS->isIndirect()) {
      forceIdea = true;
    }
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
  return this->releaseSlice(sliceIter);
}

void LLCStreamEngine::processLoadComputeSlice(LLCDynamicStreamPtr dynS,
                                              LLCStreamSlicePtr slice) {
  const auto &sliceId = slice->getSliceId();
  // Schedule the computation.
  bool allLoadComputeValueReady = true;
  for (auto elementIdx = sliceId.getStartIdx();
       elementIdx < sliceId.getEndIdx(); ++elementIdx) {
    auto element = dynS->getElementPanic(elementIdx, "ProcessLoadComputeSlice");
    if (element->isReady() && !element->isComputationScheduled() &&
        !element->isComputedValueReady()) {
      this->pushReadyComputation(element);
    }
    if (!element->isComputedValueReady()) {
      allLoadComputeValueReady = false;
    }
  }
  if (!allLoadComputeValueReady) {
    return;
  }
  // We can send back the LoadComputeValue back to core.
  // It is actually quite tricky to slice for LoadComputeStream.
  if (sliceId.getNumElements() > 1) {
    LLC_SLICE_PANIC(sliceId, "Multi-Element Slice for LoadComputeStream.");
  }

  auto S = dynS->getStaticStream();
  bool coreNeedValue = false;
  auto dynCoreS = S->getDynamicStream(dynS->getDynamicStreamId());
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  Addr paddr = 0;
  assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
  auto paddrLine = makeLineAddress(paddr);
  DataBlock loadValueBlock;
  int payloadSize = 0;
  for (auto elementIdx = sliceId.getStartIdx();
       elementIdx < sliceId.getEndIdx(); ++elementIdx) {
    auto element = dynS->getElementPanic(elementIdx, "ProcessLoadComputeSlice");
    const auto &loadComputeValue = element->getComputedValue();

    int sliceOffset;
    int elementOffset;
    int overlapSize =
        element->computeOverlap(sliceId.vaddr, RubySystem::getBlockSizeBytes(),
                                sliceOffset, elementOffset);
    payloadSize += S->getCoreElementSize();

    /**
     * Copy the value from LoadComputeValue to LoadValueBlock.
     * For simplicity we just copy MemElementSize, but the real data
     * size should be CoreElementSize. But this is OK as long as the
     * user only uses the first CoreElementSize bytes' data.
     */
    auto valuePtr = loadComputeValue.uint8Ptr(elementOffset);
    loadValueBlock.setData(valuePtr, sliceOffset, overlapSize);
  }

  // TotalOverlapSize should never exceed the line size.
  if (payloadSize > RubySystem::getBlockSizeBytes()) {
    payloadSize = RubySystem::getBlockSizeBytes();
  }

  if (coreNeedValue) {
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(), payloadSize /* payloadSize */,
        0 /* Line offset */);
    S->statistic.numLLCSentSlice++;
    S->se->numLLCSentSlice++;
    LLC_SLICE_DPRINTF(sliceId,
                      "Send LoadComputeValue to MLC: PAddrLine %#x "
                      "Data %s PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  } else {
    LLC_SLICE_DPRINTF(sliceId,
                      "Not send LoadComputeValue to MLC: PAddrLine %#x Data %s "
                      "PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  }

  /**
   * Send the data to receiver stream.
   */
  for (const auto &recvConfig : dynS->sendToConfigs) {
    LLC_SLICE_DPRINTF(sliceId,
                      "Send LoadComputeValue to ReceiverStream: %s "
                      "Data %s PayloadSize %d.\n",
                      recvConfig->dynamicId, loadValueBlock, payloadSize);
    this->issueStreamDataToLLC(dynS, sliceId, loadValueBlock, recvConfig,
                               payloadSize);
  }
  slice->setLoadComputeValueSent();
}

void LLCStreamEngine::processAtomicOrUpdateSlice(
    LLCDynamicStreamPtr dynS, const DynamicStreamSliceId &sliceId,
    const DataBlock &storeValueBlock) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  auto S = dynS->getStaticStream();
  bool coreNeedValue = false;
  auto dynCoreS = S->getDynamicStream(dynS->getDynamicStreamId());
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  /**
   * Speical case for the second request for IndirectAtomicStream
   * with core usage. We just need to send back an Ack.
   */
  if (dynS->isIndirect() && S->isAtomicComputeStream()) {
    auto elementIdx = sliceId.getStartIdx();
    auto element = dynS->getElementPanic(
        elementIdx, "Check IndirectAtomicElement second request.");
    if (element->hasFirstIndirectAtomicReqSeen()) {
      // This is the second time, should already be handled in
      // receiveStreamIndirectRequest().
      LLC_SLICE_PANIC(sliceId, "[Commit] Atomic should be release when "
                               "receiving the second request.");
    }
  }

  // The final value return to the core.
  DataBlock loadValueBlock;
  uint32_t totalPayloadSize = 0;
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element =
        dynS->getElementPanic(idx, "Process slice of Atomic/UpdateStream");
    LLC_SLICE_DPRINTF(sliceId, "TriggerUpdate for element %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isReady()) {
      // Not ready yet. Break.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu not ready while we are triggering update.",
                      idx);
    }
    if (!element->areBaseElementsReady()) {
      // We are still waiting for base elements.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu has base element not ready when updating.",
                      idx);
    }
    uint32_t payloadSize = 0;
    if (S->isAtomicComputeStream()) {
      this->triggerAtomic(dynS, element, sliceId, storeValueBlock,
                          loadValueBlock, payloadSize);
    } else {
      this->triggerUpdate(dynS, element, sliceId, storeValueBlock,
                          loadValueBlock, payloadSize);
    }
    totalPayloadSize += payloadSize;
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    this->issueStreamAckToMLC(sliceId);
  }
}

void LLCStreamEngine::performStore(Addr paddr, int size, const uint8_t *value) {
  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support store stream without BackingStore.");
  assert((paddr % RubySystem::getBlockSizeBytes()) + size <=
             RubySystem::getBlockSizeBytes() &&
         "Can not store to multi-line elements.");
  RequestPtr req =
      std::make_shared<Request>(paddr, size, 0 /* Flags */, 0 /* MasterId */);
  PacketPtr pkt = Packet::createWrite(req);
  pkt->dataStaticConst(value);
  rubySystem->getPhysMem()->functionalAccess(pkt);
  delete pkt;
}

PacketPtr
LLCStreamEngine::createAtomicPacket(Addr vaddr, Addr paddr, int size,
                                    std::unique_ptr<StreamAtomicOp> atomicOp) {
  /**
   * Create the packet.
   */
  MasterID masterId = 0;
  Addr pc = 0;
  int contextId = 0;

  Request::Flags flags;
  flags.set(Request::ATOMIC_RETURN_OP);
  RequestPtr req = std::make_shared<Request>(vaddr, size, flags, masterId, pc,
                                             contextId, std::move(atomicOp));
  req->setPaddr(paddr);
  PacketPtr pkt = Packet::createWrite(req);
  // Fake some data.
  uint8_t *pkt_data = new uint8_t[req->getSize()];
  pkt->dataDynamic(pkt_data);
  return pkt;
}

std::pair<uint64_t, bool> LLCStreamEngine::performStreamAtomicOp(
    LLCDynamicStreamPtr dynS, LLCStreamElementPtr element, Addr elementPAddr,
    const DynamicStreamSliceId &sliceId) {
  assert(sliceId.getNumElements() == 1 &&
         "Can not support multi-element atomic op.");
  auto S = dynS->getStaticStream();
  auto elementSize = S->getMemElementSize();

  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support atomicrmw stream without BackingStore.");
  assert(elementSize <= 8 && "At most 8 byte data.");
  assert((elementPAddr % RubySystem::getBlockSizeBytes()) + elementSize <=
             RubySystem::getBlockSizeBytes() &&
         "Can not atomicrmw to multi-line elements.");

  /**
   * Create the atomic op.
   */
  const auto &formalParams = dynS->configData->storeFormalParams;
  FIFOEntryIdx entryIdx(
      sliceId.getDynStreamId(),
      LLVMDynamicInst::INVALID_SEQ_NUM /* Fake ConfigSeqNum */);
  entryIdx.entryIdx = sliceId.getStartIdx();
  auto getBaseStreamValue = [element](uint64_t baseStreamId) -> StreamValue {
    return element->getBaseStreamValue(baseStreamId);
  };
  auto atomicOp =
      S->setupAtomicOp(entryIdx, elementSize, formalParams, getBaseStreamValue);

  /**
   * Create the packet.
   */
  auto pkt = this->createAtomicPacket(element->vaddr, elementPAddr, elementSize,
                                      std::move(atomicOp));
  /**
   * Send to backing store to perform atomic op.
   */
  rubySystem->getPhysMem()->functionalAccess(pkt);
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Functional accessed pkt, isWrite %d, vaddr "
                     "%#x, paddr %#x, size %d.\n",
                     pkt->isWrite(), pkt->req->getVaddr(), pkt->getAddr(),
                     pkt->getSize());

  // Get the loaded value.
  uint64_t loadedValue = 0;
  bool memoryModified = false;
  {
    auto atomicOp = dynamic_cast<StreamAtomicOp *>(pkt->getAtomicOp());
    loadedValue = atomicOp->getLoadedValue().front();
    memoryModified = atomicOp->modifiedMemory();
  }

  // Don't forget to release the packet.
  delete pkt;

  return std::make_pair(loadedValue, memoryModified);
}

void LLCStreamEngine::pushReadyComputation(LLCStreamElementPtr &element) {
  LLC_S_DPRINTF(element->dynStreamId,
                "%llu: Push ready computation %llu. Ready %d Infly %d.\n",
                this->controller->curCycle(), element->idx,
                this->readyComputations.size(), this->inflyComputations.size());
  assert(element->areBaseElementsReady() && "Element is not ready yet.");
  if (!element->isNDCElement) {
    auto dynS = LLCDynamicStream::getLLCStream(element->dynStreamId);
    if (!dynS) {
      LLC_ELEMENT_DPRINTF(element, "Skip computation as Stream is released.\n");
      return;
    }
    if (!dynS->hasComputation()) {
      LLC_ELEMENT_PANIC(element, "Stream has no computation.");
    }
    dynS->incompleteComputations++;
  }
  this->readyComputations.emplace_back(element);
  element->scheduledComputation(this->controller->curCycle());
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::pushInflyComputation(LLCStreamElementPtr &element,
                                           const StreamValue &result,
                                           Cycles &latency) {
  const int maxInflyComputation =
      this->controller->myParams->llc_stream_engine_max_infly_computation;
  assert(this->inflyComputations.size() < maxInflyComputation &&
         "Too many infly results.");
  assert(latency < 1024 && "Latency too long.");

  auto S = element->S;
  // For now we don't bother add the stats to the core in my bank.
  S->recordComputationInCoreStats();

  int numMicroOps = S->getComputationNumMicroOps();
  auto &statistic = S->statistic;
  this->controller->m_statLLCScheduledComputation++;
  this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
  this->recordComputationMicroOps(S);
  statistic.numLLCComputation++;
  statistic.numLLCComputationComputeLatency += latency;
  statistic.numLLCComputationWaitLatency +=
      this->controller->curCycle() - element->getComputationScheduledCycle();

  Cycles readyCycle = this->controller->curCycle() + latency;
  for (auto iter = this->inflyComputations.rbegin(),
            end = this->inflyComputations.rend();
       iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      this->inflyComputations.emplace(iter.base(), element, result, readyCycle);
      return;
    }
  }
  this->inflyComputations.emplace_front(element, result, readyCycle);
}

void LLCStreamEngine::recordComputationMicroOps(Stream *S) {
  auto microOps = S->getComputationNumMicroOps();
  auto category = S->getComputationCategory();

#define record_micro_ops(Addr, Compute)                                        \
  if (category.first == Stream::ComputationType::Compute &&                    \
      category.second == Stream::ComputationAddressPattern::Addr) {            \
    this->controller->m_statLLCScheduled##Addr##Compute##MicroOps += microOps; \
  }
  record_micro_ops(Affine, LoadCompute);
  record_micro_ops(Affine, StoreCompute);
  record_micro_ops(Affine, AtomicCompute);
  record_micro_ops(Affine, Update);
  record_micro_ops(Affine, Reduce);
  record_micro_ops(Indirect, LoadCompute);
  record_micro_ops(Indirect, StoreCompute);
  record_micro_ops(Indirect, AtomicCompute);
  record_micro_ops(Indirect, Update);
  record_micro_ops(Indirect, Reduce);
  record_micro_ops(PointerChase, LoadCompute);
  record_micro_ops(PointerChase, StoreCompute);
  record_micro_ops(PointerChase, AtomicCompute);
  record_micro_ops(PointerChase, Update);
  record_micro_ops(PointerChase, Reduce);
  record_micro_ops(MultiAffine, LoadCompute);
  record_micro_ops(MultiAffine, StoreCompute);
  record_micro_ops(MultiAffine, AtomicCompute);
  record_micro_ops(MultiAffine, Update);
  record_micro_ops(MultiAffine, Reduce);
#undef record_micro_ops
}

void LLCStreamEngine::startComputation() {
  int startedComputation = 0;
  const int computationWidth =
      this->controller->getLLCStreamEngineComputeWidth();
  const int maxInflyComputation =
      this->controller->myParams->llc_stream_engine_max_infly_computation;
  while (startedComputation < computationWidth &&
         !this->readyComputations.empty() &&
         this->inflyComputations.size() < maxInflyComputation) {
    auto &element = this->readyComputations.front();
    auto S = element->S;
    Cycles latency = S->getEstimatedComputationLatency();

    if (S->isSIMDComputation()) {
      /**
       * Here we charge extra latency for SIMD computation.
       */
      latency += Cycles(this->controller->myParams->llc_access_core_simd_delay);
    }

    auto forceZeroLat =
        this->controller->isLLCStreamEngineZeroComputeLatencyEnabled();
    if (forceZeroLat) {
      latency = Cycles(0);
    }
    /**
     * For IndirectReductionStream, we separate out charging the
     * latency from the real computation. Here we charge the latency,
     * but the real computation is left in completeComputation().
     */
    StreamValue result;

    if (element->isNDCElement) {
      /**
       * StreamNDC elements are handled by LLCStreamNDCController.
       */
      if (!this->ndcController->computeStreamElementValue(element, result)) {
        LLC_ELEMENT_DPRINTF(element,
                            "Discard NDC computation as stream is released.\n");
        this->readyComputations.pop_front();
        continue;
      }
    } else {
      /**
       * Normal Stream Computing.
       */
      auto dynS = LLCDynamicStream::getLLCStream(element->dynStreamId);
      if (!dynS) {
        LLC_ELEMENT_DPRINTF(element,
                            "Discard computation as stream is released.\n");
        this->readyComputations.pop_front();
        continue;
      }

      if (!dynS->isIndirectReduction()) {
        LLC_ELEMENT_DPRINTF(element,
                            "Start computation. Latency %llu (ZeroLat %d).\n",
                            latency, forceZeroLat);
        result = dynS->computeStreamElementValue(element);
      } else {
        LLC_ELEMENT_DPRINTF(element,
                            "Start IndirectReduction fake computation. Latency "
                            "%llu (ZeroLat %d).\n",
                            latency, forceZeroLat);
        result.fill(0);
      }
    }
    this->pushInflyComputation(element, result, latency);

    this->readyComputations.pop_front();
    startedComputation++;
  }
}

void LLCStreamEngine::completeComputation() {
  // We don't charge complete width.
  auto curCycle = this->controller->curCycle();
  while (!this->inflyComputations.empty()) {
    auto &computation = this->inflyComputations.front();
    auto &element = computation.element;
    if (computation.readyCycle > curCycle) {
      LLC_ELEMENT_DPRINTF(element,
                          "Cannot complete computation, readyCycle "
                          "%llu, curCycle %llu.\n",
                          computation.readyCycle, curCycle);
      break;
    }
    LLC_ELEMENT_DPRINTF(element, "Complete computation.\n");
    if (element->isNDCElement) {
      this->ndcController->completeComputation(element, computation.result);
    } else {
      auto dynS = LLCDynamicStream::getLLCStream(element->dynStreamId);
      if (dynS) {
        dynS->completeComputation(this, element, computation.result);
      } else {
        LLC_ELEMENT_DPRINTF(
            element, "Discard computation result as stream is released.\n");
      }
    }
    this->inflyComputations.pop_front();
  }
}